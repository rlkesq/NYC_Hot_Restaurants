{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, fnmatch\n",
    "import matplotlib as mplt\n",
    "from scipy import stats \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Census Data\n",
    "\n",
    "### The United States Census Bureau (USCB) conducts the decennial 'census' required under the United States Constitution, but also conducts many other information gathering and desemination programs.  Indeed, nearly $100 billion of the federal budget is allocated among local geographical units, such as census tracts, based upon those surveys and estimates.  One of the most important such surveys is the American Community Survey (ACS), conducted annually and analyzed at different geographic levels on an annual basis and on a five-year basis projecting to the then current year based upon the annual surveys taken over the period.  The five-year ACS Surveys take the analysis down to the level of census tracts and, in most cases, block groups:  these surveys form the nucleus of the data for our analysis here.\n",
    "\n",
    "###  In this research, I am taking data from the five-year ACS Surveys for 2012 (i.e., providing data gathered from 2007-2012) through the 2017 five-year survey that was released in stages starting in November, 2018:  the 2017 ACS survey is the most recent comprehensive data for our purposes.  Of the thousands of tables included in the survey, I have winnowed the selection down to what I believe to be six particularly relevant features for our study of households, in each case evaluated at the tract level.  There are roughly 220 census tracts covering the island of Manhattan, of roughly equal population density: in midtown and downtown, each tract typically includes 15-20 blocks. \n",
    "\n",
    "### In its tables, the USCB distinguishes between family-based data and household-based data.  The latter looks particularly to the individuals living in a single housing unit, without necessary regard to any relationship among them.  More detail can be found regarding this concept and its consequences in the survey information published by the USCB.  In general, for some survey purposes that will be relevant here, the attributes of a \"housholder\" is studied: this references a leader in the housing unit without regard to whether that unit is a single family home or, as will be nearly universally the situation in cases in which we are interested here, an owned or leased condominium or coop unit. We will look in detail at that data, with regard to the number of occupants [Table B11001], the highest educational level achieved by the householder [Table B15003], the twelve-month household income [Table B19001], the receipt of any passive income (interest, dividends, rent) by the household [Table B19054], the age of the structure in which the household unit is situated [Table B25034], and the monthly rent asked of the household unit [Table B25061].\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Following my review of literature and experience in financing of economic development, my hypothesis is that successful rapid development of a restaurant-friendly neighborhood may be corollated with upward momentum in education, income, rents and investments of an upwardly mobile residential community.  The study of the census data is intended to provide a resource of features for our cluster analysis.  In this module, we will upload the data sets into Pandas dataframes, clean and normalize it, and then use a linear regression method to evaluate the upward (or downward) trend (or what I refer to as 'momentum') for each feature and on a census tract basis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading the Data\n",
    "\n",
    "#### We will be uploading five tables from each of six five-year surveys, referred to here as 'ACSnn_5YR' (referring to the nn-year American Communities five-year survey), into Pandas dataframes.  The raw data is located in the 'Data_for_NYCHR' that is part of the project repository.  The nomenclature also will refer to the specific tables (described above) from each survey.  All census data used here has been obtained from the USCB on its open-data website at: https://www.census.gov/acs/www/data/data-tables-and-tools/american-factfinder/.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current Rent Asked (Table B25061)\n",
    "\n",
    "### Unique to Table B25061, the table fields were modified during the period of our study, to provide a more detailed differentiation of rents above $2,000/month.  That modification is reflected in the module below.  The fields of each of the other tables have remained consistent throughout the 2012-2017 releases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACS_list = [('ACS17_5YR_FULL_N',True),('ACS16_5YR_FULL_N',True),('ACS15_5YR_FULL_N',True),('ACS14_5YR_FULL_N',False),\n",
    "            ('ACS13_5YR_FULL_N',False),('ACS12_5YR_FULL_N',False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "B25061_current_fields = ['GEO.id2','HD01_VD01','HD01_VD22','HD01_VD23','HD01_VD24','HD01_VD25']\n",
    "current_names = ['Total','>$2,000','<$2,500','<$3,000','>$3,500']\n",
    "B25061_original_fields = ['GEO.id2','HD01_VD01','HD01_VD22']\n",
    "original_names = ['Total','>$2,000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/users/richardkornblith/Data_Science/NYCHR/Data_for_NYCHR/ACS17_5YR_FULL_N/\n",
      "/users/richardkornblith/Data_Science/NYCHR/Data_for_NYCHR/ACS16_5YR_FULL_N/\n",
      "/users/richardkornblith/Data_Science/NYCHR/Data_for_NYCHR/ACS15_5YR_FULL_N/\n",
      "/users/richardkornblith/Data_Science/NYCHR/Data_for_NYCHR/ACS14_5YR_FULL_N/\n",
      "/users/richardkornblith/Data_Science/NYCHR/Data_for_NYCHR/ACS13_5YR_FULL_N/\n",
      "/users/richardkornblith/Data_Science/NYCHR/Data_for_NYCHR/ACS12_5YR_FULL_N/\n"
     ]
    }
   ],
   "source": [
    "pds={}\n",
    "\n",
    "for i in range(len(ACS_list)):\n",
    "    subdir=ACS_list[i]\n",
    "    tr = '/users/richardkornblith/Data_Science/NYCHR/Data_for_NYCHR/'+subdir[0]+'/'\n",
    "    print(tr)\n",
    "    csv_file = fnmatch.filter(os.listdir(tr),'*61*with_ann.csv')\n",
    "    full_path = tr+csv_file[0]\n",
    "    if ACS_list[i][1]:\n",
    "        cols = B25061_current_fields\n",
    "        col_names = current_names\n",
    "    else:\n",
    "        cols = B25061_original_fields\n",
    "        col_names = original_names\n",
    "    df_t = pd.read_csv(full_path, index_col='GEO.id2',usecols=cols)\n",
    "    df_t.columns = [ACS_list[i][0][0:5]+\" \"+col_names[j] for j in range(len(col_names))]\n",
    "    df_t.drop(labels='Id2', inplace=True)\n",
    "    pds[ACS_list[i][0]]=df_t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Because of the shift in the rent survey fields in 2015, described above, we align the information for 2015, 2016 and 2017 with that from prior years.  We will do that by combining the counts of all households with rental levels higher than two thousand in the later years and compare those aggregates to the counts of households in the highest range for the earlier years.  This step will not be required for the tables addressing the remaining features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ACS17 Total', 'ACS17 >$2,000', 'ACS17 <$2,500', 'ACS17 <$3,000',\n",
      "       'ACS17 >$3,500', 'ACS16 Total', 'ACS16 >$2,000', 'ACS16 <$2,500',\n",
      "       'ACS16 <$3,000', 'ACS16 >$3,500', 'ACS15 Total', 'ACS15 >$2,000',\n",
      "       'ACS15 <$2,500', 'ACS15 <$3,000', 'ACS15 >$3,500', 'ACS14 Total',\n",
      "       'ACS14 >$2,000', 'ACS13 Total', 'ACS13 >$2,000', 'ACS12 Total',\n",
      "       'ACS12 >$2,000', 'ACS17 >$2,000 Agg', 'ACS16 >$2,000 Agg',\n",
      "       'ACS15 >$2,000 Agg'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACS17 Total</th>\n",
       "      <th>ACS17 &gt;$2,000</th>\n",
       "      <th>ACS17 &lt;$2,500</th>\n",
       "      <th>ACS17 &lt;$3,000</th>\n",
       "      <th>ACS17 &gt;$3,500</th>\n",
       "      <th>ACS16 Total</th>\n",
       "      <th>ACS16 &gt;$2,000</th>\n",
       "      <th>ACS16 &lt;$2,500</th>\n",
       "      <th>ACS16 &lt;$3,000</th>\n",
       "      <th>ACS16 &gt;$3,500</th>\n",
       "      <th>...</th>\n",
       "      <th>ACS15 &gt;$3,500</th>\n",
       "      <th>ACS14 Total</th>\n",
       "      <th>ACS14 &gt;$2,000</th>\n",
       "      <th>ACS13 Total</th>\n",
       "      <th>ACS13 &gt;$2,000</th>\n",
       "      <th>ACS12 Total</th>\n",
       "      <th>ACS12 &gt;$2,000</th>\n",
       "      <th>ACS17 &gt;$2,000 Agg</th>\n",
       "      <th>ACS16 &gt;$2,000 Agg</th>\n",
       "      <th>ACS15 &gt;$2,000 Agg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GEO.id2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36061000100</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36061000201</th>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36061000202</th>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36061000500</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36061000600</th>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ACS17 Total  ACS17 >$2,000  ACS17 <$2,500  ACS17 <$3,000  \\\n",
       "GEO.id2                                                                 \n",
       "36061000100            0              0              0              0   \n",
       "36061000201           82              0              0              0   \n",
       "36061000202           98              0              0              0   \n",
       "36061000500            0              0              0              0   \n",
       "36061000600           79              0              0              0   \n",
       "\n",
       "             ACS17 >$3,500  ACS16 Total  ACS16 >$2,000  ACS16 <$2,500  \\\n",
       "GEO.id2                                                                 \n",
       "36061000100              0            0              0              0   \n",
       "36061000201              0           59              0              0   \n",
       "36061000202              0           44              0              0   \n",
       "36061000500              0            0              0              0   \n",
       "36061000600              0            0              0              0   \n",
       "\n",
       "             ACS16 <$3,000  ACS16 >$3,500  ...  ACS15 >$3,500  ACS14 Total  \\\n",
       "GEO.id2                                    ...                               \n",
       "36061000100              0              0  ...              0            0   \n",
       "36061000201              0              0  ...              0           96   \n",
       "36061000202              0              0  ...              0           44   \n",
       "36061000500              0              0  ...              0            0   \n",
       "36061000600              0              0  ...              0           65   \n",
       "\n",
       "             ACS14 >$2,000  ACS13 Total  ACS13 >$2,000  ACS12 Total  \\\n",
       "GEO.id2                                                               \n",
       "36061000100              0            0              0            0   \n",
       "36061000201              0           86              0           45   \n",
       "36061000202              0           46              0           32   \n",
       "36061000500              0            0              0            0   \n",
       "36061000600              0          105              0          106   \n",
       "\n",
       "             ACS12 >$2,000  ACS17 >$2,000 Agg  ACS16 >$2,000 Agg  \\\n",
       "GEO.id2                                                            \n",
       "36061000100              0                  0                  0   \n",
       "36061000201              0                  0                  0   \n",
       "36061000202              0                  0                  0   \n",
       "36061000500              0                  0                  0   \n",
       "36061000600              0                  0                  0   \n",
       "\n",
       "             ACS15 >$2,000 Agg  \n",
       "GEO.id2                         \n",
       "36061000100                  0  \n",
       "36061000201                  0  \n",
       "36061000202                  0  \n",
       "36061000500                  0  \n",
       "36061000600                  0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rent=pd.concat([pds[ACS_list[0][0]],pds[ACS_list[1][0]],pds[ACS_list[2][0]],pds[ACS_list[3][0]],pds[ACS_list[4][0]],pds[ACS_list[5][0]]],axis=1)\n",
    "rent_int=rent.astype(int)\n",
    "\n",
    "agg17=(rent_int['ACS17 >$2,000']+rent_int['ACS17 <$2,500']+rent_int['ACS17 <$3,000']+rent_int['ACS17 >$3,500'])\n",
    "agg16 = (rent_int['ACS16 >$2,000']+rent_int['ACS16 <$2,500']+rent_int['ACS16 <$3,000']+rent_int['ACS16 >$3,500'])\n",
    "agg15 = (rent_int['ACS15 >$2,000']+rent_int['ACS15 <$2,500']+rent_int['ACS15 <$3,000']+rent_int['ACS15 >$3,500'])\n",
    "\n",
    "rent_int['ACS17 >$2,000 Agg'] = agg17\n",
    "rent_int['ACS16 >$2,000 Agg'] = agg16\n",
    "rent_int['ACS15 >$2,000 Agg'] = agg15\n",
    "print(rent_int.columns)\n",
    "rent_int.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now we normalize the data by division of the number of households reporting rent in excess of $2,000/month \n",
    "# by the total number of households reporting rent in the respective surveys.  In the cases where no households reported in\n",
    "# a particular survey, the resulting division by zero, resulting in a missing data 'NaN' entry, will be addressed below.\n",
    "\n",
    "rent_int['2017 Values']= rent_int['ACS17 >$2,000 Agg'].div(rent_int['ACS17 Total'],axis=0)\n",
    "rent_int['2016 Values']= rent_int['ACS16 >$2,000 Agg'].div(rent_int['ACS16 Total'],axis=0)\n",
    "rent_int['2015 Values']= rent_int['ACS15 >$2,000 Agg'].div(rent_int['ACS15 Total'],axis=0)\n",
    "rent_int['2014 Values']= rent_int['ACS14 >$2,000'].div(rent_int['ACS14 Total'],axis=0)\n",
    "rent_int['2013 Values']= rent_int['ACS13 >$2,000'].div(rent_int['ACS13 Total'],axis=0)\n",
    "rent_int['2012 Values']= rent_int['ACS12 >$2,000'].div(rent_int['ACS12 Total'],axis=0)\n",
    "rent_int_idx = rent_int.reset_index(level=0, inplace=False)\n",
    "# rent_int_idx.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Now we will address the missing data. We first will interpolate between valid data entries and after that we will try backfilling.\n",
    "# Any remaining instances that have missing data will be dropped.  \n",
    "# As will be seen, relatively few relevant census tracts are lost through this procedure:\n",
    " \n",
    "\n",
    "rent_int_clean= pd.DataFrame(rent_int_idx[['2017 Values','2016 Values','2015 Values','2014 Values','2013 Values','2012 Values']])\n",
    "y=rent_int_clean.interpolate(method='linear',axis=1, inplace=False)\n",
    "z=y.fillna(method='bfill', axis=1)\n",
    "z['Tract']=rent_int_idx.loc[:,'GEO.id2']\n",
    "zz=z.dropna(axis=0)\n",
    "rent_moment = zz.reset_index(drop=True, inplace=False)\n",
    "# rent_moment.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will determine the momentum of the population of households on each feature by taking a straight line linear regression of the six years of data sets.  As an aside, there nearly certainly are more available, but complex, methods for measuring this momentum: however, the scipy stats.linregress method should provide adequate trend information and statistical analysis for out purposes.  Here, we create a dictionary of results, one entry for each census tract that had valid data: the values in each entry are the slope (m) and the intercept (b) for the line, and the correlation factor (r), p-value (p) and standard error (std_err) for the fit to the data.  A cursory review of the results reveals a wide dispersion in slopes (momentum), with remarkably strong statistics. This is reassuring, as the principal reason for including as many as six data points for each tract was to reduce the impact of statistical noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbs=pd.Series([0,1,2,3,4,5])\n",
    "results = {}\n",
    "for i in range(len(rent_moment)):\n",
    "    testdata = pd.Series(rent_moment.loc[i,['2012 Values','2013 Values','2014 Values','2015 Values','2016 Values','2017 Values']])\n",
    "    m,b,r,p,std_err = stats.linregress(numbs.astype(float), testdata.astype(float))\n",
    "    results[i]=(m,b,r,p,std_err)\n",
    "\n",
    "len(results)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading and Analyzing the Remaining Feature Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table B11001 (Household Type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table B11001 addresses the composition of the members of a household unit.  It discriminates between households comprising two or more members of a 'family' and those comprising one or more persons who are not of the same family; within the latter group, separate features include households of a persons living alone, on the one hand, and those of two or more persons. For purposes of our study, I have included only the latter two features since (i) the category of family households is the converse of the category of total nonfamily households (given the total number of responses); (ii) in the case of units occupied by families, no distinction is made between those with and those without children of a young age that might be relevant to decisions regarding dining at restaurants of the type contemplated in this study; but (iii) it is resonable to expect that the restaurant behavior of households comprising only one person would be different from that of households comprising two or more unrelated persons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the avoidance of confusion, we will continue to use the ACS_list of tuples, notwithstanding that the second member of each tuple was\n",
    "# introduced solely to accommodate the change in fields on B25061, discussed above.\n",
    "\n",
    "ACS_list = [('ACS17_5YR_FULL_N',True),('ACS16_5YR_FULL_N',True),('ACS15_5YR_FULL_N',True),('ACS14_5YR_FULL_N',False),\n",
    "            ('ACS13_5YR_FULL_N',False),('ACS12_5YR_FULL_N',False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "B11001_current_fields = ['GEO.id2','HD01_VD01','HD01_VD08','HD01_VD09']\n",
    "current_names = ['Total','HH Living Alone','HH Not Living Alone']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pds={}\n",
    "\n",
    "for i in range(len(ACS_list)):\n",
    "    subdir=ACS_list[i]\n",
    "    tr = '/users/richardkornblith/Data_Science/NYCHR/Data_for_NYCHR/'+subdir[0]+'/'\n",
    "    csv_file = fnmatch.filter(os.listdir(tr),'*01*with_ann.csv')\n",
    "    full_path = tr+csv_file[0]\n",
    "    cols = B11001_current_fields\n",
    "    col_names = current_names\n",
    "    df_t = pd.read_csv(full_path, index_col='GEO.id2',usecols=cols)\n",
    "    df_t.columns = [ACS_list[i][0][0:5]+\" \"+col_names[j] for j in range(len(col_names))]\n",
    "    df_t.drop(labels='Id2', inplace=True)\n",
    "    pds[ACS_list[i][0]]=df_t\n",
    "    \n",
    "# pds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hhstat=pd.concat([pds[ACS_list[0][0]],pds[ACS_list[1][0]],pds[ACS_list[2][0]],pds[ACS_list[3][0]],pds[ACS_list[4][0]],pds[ACS_list[5][0]]],axis=1)\n",
    "hhstat_int=hhstat.astype(int)\n",
    "# hhstat_int.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 288 entries, 36061000100 to 36061031900\n",
      "Data columns (total 18 columns):\n",
      "ACS17 Total                  288 non-null int64\n",
      "ACS17 HH Living Alone        280 non-null float64\n",
      "ACS17 HH Not Living Alone    280 non-null float64\n",
      "ACS16 Total                  288 non-null int64\n",
      "ACS16 HH Living Alone        280 non-null float64\n",
      "ACS16 HH Not Living Alone    280 non-null float64\n",
      "ACS15 Total                  288 non-null int64\n",
      "ACS15 HH Living Alone        280 non-null float64\n",
      "ACS15 HH Not Living Alone    280 non-null float64\n",
      "ACS14 Total                  288 non-null int64\n",
      "ACS14 HH Living Alone        279 non-null float64\n",
      "ACS14 HH Not Living Alone    279 non-null float64\n",
      "ACS13 Total                  288 non-null int64\n",
      "ACS13 HH Living Alone        279 non-null float64\n",
      "ACS13 HH Not Living Alone    279 non-null float64\n",
      "ACS12 Total                  288 non-null int64\n",
      "ACS12 HH Living Alone        279 non-null float64\n",
      "ACS12 HH Not Living Alone    279 non-null float64\n",
      "dtypes: float64(12), int64(6)\n",
      "memory usage: 42.8+ KB\n"
     ]
    }
   ],
   "source": [
    "## Now we normalize the data by division of the number of households reporting occupancy status  \n",
    "# by the total number of households reporting rent in the respective surveys.  In the cases where no households reported in\n",
    "# a particular survey, the resulting division by zero, resulting in a missing data 'NaN' entry, will be addressed below.\n",
    "\n",
    "hhstat_int['ACS17 HH Living Alone']= hhstat_int['ACS17 HH Living Alone'].div(hhstat_int['ACS17 Total'],axis=0)\n",
    "hhstat_int['ACS17 HH Not Living Alone']= hhstat_int['ACS17 HH Not Living Alone'].div(hhstat_int['ACS17 Total'],axis=0)\n",
    "hhstat_int['ACS16 HH Living Alone']= hhstat_int['ACS16 HH Living Alone'].div(hhstat_int['ACS16 Total'],axis=0)\n",
    "hhstat_int['ACS16 HH Not Living Alone']= hhstat_int['ACS16 HH Not Living Alone'].div(hhstat_int['ACS16 Total'],axis=0)\n",
    "hhstat_int['ACS15 HH Living Alone']= hhstat_int['ACS15 HH Living Alone'].div(hhstat_int['ACS15 Total'],axis=0)\n",
    "hhstat_int['ACS15 HH Not Living Alone']= hhstat_int['ACS15 HH Not Living Alone'].div(hhstat_int['ACS15 Total'],axis=0)\n",
    "hhstat_int['ACS14 HH Living Alone']= hhstat_int['ACS14 HH Living Alone'].div(hhstat_int['ACS14 Total'],axis=0)\n",
    "hhstat_int['ACS14 HH Not Living Alone']= hhstat_int['ACS14 HH Not Living Alone'].div(hhstat_int['ACS14 Total'],axis=0)                                                                             \n",
    "hhstat_int['ACS13 HH Living Alone']= hhstat_int['ACS13 HH Living Alone'].div(hhstat_int['ACS13 Total'],axis=0)\n",
    "hhstat_int['ACS13 HH Not Living Alone']= hhstat_int['ACS13 HH Not Living Alone'].div(hhstat_int['ACS13 Total'],axis=0)                                                                             \n",
    "hhstat_int['ACS12 HH Living Alone']= hhstat_int['ACS12 HH Living Alone'].div(hhstat_int['ACS12 Total'],axis=0)\n",
    "hhstat_int['ACS12 HH Not Living Alone']= hhstat_int['ACS12 HH Not Living Alone'].div(hhstat_int['ACS12 Total'],axis=0)\n",
    "hhstat_int_idx = hhstat_int.reset_index(level=0, inplace=False)\n",
    "# hhstat_int_idx.info()\n",
    "hhstat_int.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 280 entries, 0 to 279\n",
      "Data columns (total 13 columns):\n",
      "ACS17 HH Living Alone        280 non-null float64\n",
      "ACS17 HH Not Living Alone    280 non-null float64\n",
      "ACS16 HH Living Alone        280 non-null float64\n",
      "ACS16 HH Not Living Alone    280 non-null float64\n",
      "ACS15 HH Living Alone        280 non-null float64\n",
      "ACS15 HH Not Living Alone    280 non-null float64\n",
      "ACS14 HH Living Alone        280 non-null float64\n",
      "ACS14 HH Not Living Alone    280 non-null float64\n",
      "ACS13 HH Living Alone        280 non-null float64\n",
      "ACS13 HH Not Living Alone    280 non-null float64\n",
      "ACS12 HH Living Alone        280 non-null float64\n",
      "ACS12 HH Not Living Alone    280 non-null float64\n",
      "Tract                        280 non-null object\n",
      "dtypes: float64(12), object(1)\n",
      "memory usage: 28.5+ KB\n"
     ]
    }
   ],
   "source": [
    "##### Now we will address the missing data. We first will interpolate between valid data entries and after that we will try backfilling.\n",
    "# Any remaining instances that have missing data will be dropped.  \n",
    "# As will be seen, relatively few relevant census tracts are lost through this procedure:\n",
    " \n",
    "\n",
    "hhstat_int_clean= pd.DataFrame(hhstat_int_idx[['ACS17 HH Living Alone', 'ACS17 HH Not Living Alone',\n",
    "       'ACS16 HH Living Alone', 'ACS16 HH Not Living Alone',\n",
    "       'ACS15 HH Living Alone', 'ACS15 HH Not Living Alone',\n",
    "       'ACS14 HH Living Alone', 'ACS14 HH Not Living Alone',\n",
    "       'ACS13 HH Living Alone', 'ACS13 HH Not Living Alone',\n",
    "       'ACS12 HH Living Alone', 'ACS12 HH Not Living Alone']])\n",
    "y=hhstat_int_clean.interpolate(method='linear',axis=1, inplace=False)\n",
    "z=y.fillna(method='bfill', axis=1)\n",
    "z['Tract']=hhstat_int_idx.loc[:,'GEO.id2']\n",
    "zz=z.dropna(axis=0)\n",
    "hhstat_moment = zz.reset_index(drop=True, inplace=False)\n",
    "hhstat_moment.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbs=pd.Series([0,1,2,3,4,5])\n",
    "# First, for Households Living Alone\n",
    "results_HHLA = {}\n",
    "for i in range(len(hhstat_moment)):\n",
    "    testdata = pd.Series(hhstat_moment.loc[i,['ACS17 HH Living Alone','ACS16 HH Living Alone', \n",
    "       'ACS15 HH Living Alone', 'ACS14 HH Living Alone','ACS13 HH Living Alone', 'ACS12 HH Living Alone']])\n",
    "    m,b,r,p,std_err = stats.linregress(numbs.astype(float), testdata.astype(float))\n",
    "    results_HHLA[i]=(m,b,r,p,std_err)\n",
    "len(results_HHLA)\n",
    "\n",
    "\n",
    "# Now, for Households Not Living Alone\n",
    "results_HHNLA = {}\n",
    "for i in range(len(hhstat_moment)):\n",
    "    testdata = pd.Series(hhstat_moment.loc[i,['ACS17 HH Living Alone','ACS16 HH Living Alone', \n",
    "       'ACS15 HH Living Alone', 'ACS14 HH Living Alone','ACS13 HH Living Alone', 'ACS12 HH Living Alone']])\n",
    "    m,b,r,p,std_err = stats.linregress(numbs.astype(float), testdata.astype(float))\n",
    "    results_HHNLA[i]=(m,b,r,p,std_err)\n",
    "len(results_HHNLA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table B15003 (Educational Attainment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table B15003 addresses the highest level of educational attainment in the household. It provides very detailed classifications of such attainment, from lower school through the Ph.D. level.  In my experience (having both a J.D. and a Ph.D.), the restaurant choices made by persons holding a Masters or lower level of attainment is quite different from that of a holder of a professional degree, and each of those is very different from the decisions made by a holder of a Ph.D. This study will utilize as features only the three highest levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACS_list = [('ACS17_5YR_FULL_N',True),('ACS16_5YR_FULL_N',True),('ACS15_5YR_FULL_N',True),('ACS14_5YR_FULL_N',False),\n",
    "            ('ACS13_5YR_FULL_N',False),('ACS12_5YR_FULL_N',False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GEO.id2', 'HD01_VD01', 'HD01_VD23', 'HD01_VD24', 'HD01_VD25']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B15003_current_fields = ['GEO.id2','HD01_VD01','HD01_VD23','HD01_VD24','HD01_VD25']\n",
    "current_names = ['Total','Masters','Professional', 'PhD']\n",
    "B15003_current_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pds={}\n",
    "\n",
    "for i in range(len(ACS_list)):\n",
    "    subdir=ACS_list[i]\n",
    "# # #     print('subdir is: ', subdir)\n",
    "    tr = '/users/richardkornblith/Data_Science/NYCHR/Data_for_NYCHR/'+subdir[0]+'/'\n",
    "# #     print ('tr is: ', tr)\n",
    "    csv_file = fnmatch.filter(os.listdir(tr),'*003*with_ann.csv')\n",
    "#     print ('csv_file is: ', fnmatch)\n",
    "    full_path = tr+csv_file[0]\n",
    "#     print('full_path is: ', full_path)\n",
    "    cols = B15003_current_fields\n",
    "    col_names = current_names\n",
    "    df_t = pd.read_csv(full_path, index_col='GEO.id2',usecols=cols)\n",
    "#     print(df_t.info())\n",
    "    df_t.columns = [ACS_list[i][0][0:5]+\" \"+col_names[j] for j in range(len(col_names))]\n",
    "    df_t.drop(labels='Id2', inplace=True)\n",
    "    pds[ACS_list[i][0]]=df_t\n",
    "    \n",
    "# pds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 288 entries, 36061000100 to 36061031900\n",
      "Data columns (total 24 columns):\n",
      "ACS17 Total           288 non-null int64\n",
      "ACS17 Masters         288 non-null int64\n",
      "ACS17 Professional    288 non-null int64\n",
      "ACS17 PhD             288 non-null int64\n",
      "ACS16 Total           288 non-null int64\n",
      "ACS16 Masters         288 non-null int64\n",
      "ACS16 Professional    288 non-null int64\n",
      "ACS16 PhD             288 non-null int64\n",
      "ACS15 Total           288 non-null int64\n",
      "ACS15 Masters         288 non-null int64\n",
      "ACS15 Professional    288 non-null int64\n",
      "ACS15 PhD             288 non-null int64\n",
      "ACS14 Total           288 non-null int64\n",
      "ACS14 Masters         288 non-null int64\n",
      "ACS14 Professional    288 non-null int64\n",
      "ACS14 PhD             288 non-null int64\n",
      "ACS13 Total           288 non-null int64\n",
      "ACS13 Masters         288 non-null int64\n",
      "ACS13 Professional    288 non-null int64\n",
      "ACS13 PhD             288 non-null int64\n",
      "ACS12 Total           288 non-null int64\n",
      "ACS12 Masters         288 non-null int64\n",
      "ACS12 Professional    288 non-null int64\n",
      "ACS12 PhD             288 non-null int64\n",
      "dtypes: int64(24)\n",
      "memory usage: 56.2+ KB\n"
     ]
    }
   ],
   "source": [
    "edstat=pd.concat([pds[ACS_list[0][0]],pds[ACS_list[1][0]],pds[ACS_list[2][0]],pds[ACS_list[3][0]],pds[ACS_list[4][0]],pds[ACS_list[5][0]]],axis=1)\n",
    "edstat_int=edstat.astype(int)\n",
    "edstat_int.head(10)\n",
    "edstat_int.columns\n",
    "edstat_int.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now we normalize the data by division of the number of households reporting a level of educational attainment of interest here \n",
    "# by the total number of households reporting educational attainment at any level in the respective surveys.  In the cases \n",
    "# where no households reported in\n",
    "# a particular survey, the resulting division by zero, resulting in a missing data 'NaN' entry, will be addressed below.\n",
    "\n",
    "edstat_int['ACS17 Masters']= edstat_int['ACS17 Masters'].div(edstat_int['ACS17 Total'],axis=0)\n",
    "edstat_int['ACS17 Professional']= edstat_int['ACS17 Professional'].div(edstat_int['ACS17 Total'],axis=0)\n",
    "edstat_int['ACS17 PhD']= edstat_int['ACS17 PhD'].div(edstat_int['ACS17 Total'],axis=0)\n",
    "edstat_int['ACS16 Masters']= edstat_int['ACS16 Masters'].div(edstat_int['ACS16 Total'],axis=0)\n",
    "edstat_int['ACS16 Professional']= edstat_int['ACS16 Professional'].div(edstat_int['ACS16 Total'],axis=0)\n",
    "edstat_int['ACS16 PhD']= edstat_int['ACS16 PhD'].div(edstat_int['ACS16 Total'],axis=0)\n",
    "edstat_int['ACS15 Masters']= edstat_int['ACS15 Masters'].div(edstat_int['ACS15 Total'],axis=0)\n",
    "edstat_int['ACS15 Professional']= edstat_int['ACS15 Professional'].div(edstat_int['ACS15 Total'],axis=0)\n",
    "edstat_int['ACS15 PhD']= edstat_int['ACS15 PhD'].div(edstat_int['ACS15 Total'],axis=0)\n",
    "edstat_int['ACS14 Masters']= edstat_int['ACS14 Masters'].div(edstat_int['ACS14 Total'],axis=0)\n",
    "edstat_int['ACS14 Professional']= edstat_int['ACS14 Professional'].div(edstat_int['ACS14 Total'],axis=0)\n",
    "edstat_int['ACS14 PhD']= edstat_int['ACS14 PhD'].div(edstat_int['ACS14 Total'],axis=0)\n",
    "edstat_int['ACS13 Masters']= edstat_int['ACS13 Masters'].div(edstat_int['ACS13 Total'],axis=0)\n",
    "edstat_int['ACS13 Professional']= edstat_int['ACS13 Professional'].div(edstat_int['ACS13 Total'],axis=0)\n",
    "edstat_int['ACS13 PhD']= edstat_int['ACS13 PhD'].div(edstat_int['ACS13 Total'],axis=0)\n",
    "edstat_int['ACS12 Masters']= edstat_int['ACS12 Masters'].div(edstat_int['ACS12 Total'],axis=0)\n",
    "edstat_int['ACS12 Professional']= edstat_int['ACS12 Professional'].div(edstat_int['ACS12 Total'],axis=0)\n",
    "edstat_int['ACS12 PhD']= edstat_int['ACS12 PhD'].div(edstat_int['ACS12 Total'],axis=0)\n",
    "edstat_int_idx = edstat_int.reset_index(level=0, inplace=False)\n",
    "# edstat_int_idx.info()\n",
    "# edstat_int.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 283 entries, 0 to 282\n",
      "Data columns (total 19 columns):\n",
      "ACS17 Masters         283 non-null float64\n",
      "ACS17 Professional    283 non-null float64\n",
      "ACS17 PhD             283 non-null float64\n",
      "ACS16 Masters         283 non-null float64\n",
      "ACS16 Professional    283 non-null float64\n",
      "ACS16 PhD             283 non-null float64\n",
      "ACS15 Masters         283 non-null float64\n",
      "ACS15 Professional    283 non-null float64\n",
      "ACS15 PhD             283 non-null float64\n",
      "ACS14 Masters         283 non-null float64\n",
      "ACS14 Professional    283 non-null float64\n",
      "ACS14 PhD             283 non-null float64\n",
      "ACS13 Masters         283 non-null float64\n",
      "ACS13 Professional    283 non-null float64\n",
      "ACS13 PhD             283 non-null float64\n",
      "ACS12 Masters         283 non-null float64\n",
      "ACS12 Professional    283 non-null float64\n",
      "ACS12 PhD             283 non-null float64\n",
      "Tract                 283 non-null object\n",
      "dtypes: float64(18), object(1)\n",
      "memory usage: 42.1+ KB\n"
     ]
    }
   ],
   "source": [
    "##### Now we will address the missing data. We first will interpolate between valid data entries and after that we will try backfilling.\n",
    "# Any remaining instances that have missing data will be dropped.  \n",
    "# As will be seen, relatively few relevant census tracts are lost through this procedure:\n",
    " \n",
    "\n",
    "edstat_int_clean= pd.DataFrame(edstat_int_idx[['ACS17 Masters', 'ACS17 Professional', 'ACS17 PhD',\n",
    "       'ACS16 Masters', 'ACS16 Professional', 'ACS16 PhD',\n",
    "       'ACS15 Masters', 'ACS15 Professional', 'ACS15 PhD',\n",
    "       'ACS14 Masters', 'ACS14 Professional', 'ACS14 PhD',\n",
    "       'ACS13 Masters', 'ACS13 Professional', 'ACS13 PhD',\n",
    "       'ACS12 Masters', 'ACS12 Professional', 'ACS12 PhD']])\n",
    "y=edstat_int_clean.interpolate(method='linear',axis=1, inplace=False)\n",
    "z=y.fillna(method='bfill', axis=1)\n",
    "z['Tract']=edstat_int_idx.loc[:,'GEO.id2']\n",
    "zz=z.dropna(axis=0)\n",
    "edstat_moment = zz.reset_index(drop=True, inplace=False)\n",
    "edstat_moment.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "283"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbs=pd.Series([0,1,2,3,4,5])\n",
    "# First, for Households Achieving Masters Degree\n",
    "results_HHMSTR = {}\n",
    "for i in range(len(edstat_moment)):\n",
    "    testdata = pd.Series(edstat_moment.loc[i,['ACS17 Masters','ACS16 Masters','ACS15 Masters', 'ACS14 Masters','ACS13 Masters', 'ACS12 Masters']])\n",
    "    m,b,r,p,std_err = stats.linregress(numbs.astype(float), testdata.astype(float))\n",
    "    results_HHMSTR[i]=(m,b,r,p,std_err)\n",
    "len(results_HHMSTR)\n",
    "\n",
    "\n",
    "# Now, for Households Achieving Professional Degree\n",
    "results_HHPRD = {}\n",
    "for i in range(len(edstat_moment)):\n",
    "    testdata = pd.Series(edstat_moment.loc[i,['ACS17 Masters','ACS16 Masters', \n",
    "       'ACS15 Masters', 'ACS14 Masters','ACS13 Masters', 'ACS12 Masters']])\n",
    "    m,b,r,p,std_err = stats.linregress(numbs.astype(float), testdata.astype(float))\n",
    "    results_HHPRD[i]=(m,b,r,p,std_err)\n",
    "len(results_HHPRD)\n",
    "\n",
    "# Finally, for Households Achieving a Ph.D.\n",
    "\n",
    "results_HHPHD = {}\n",
    "for i in range(len(edstat_moment)):\n",
    "    testdata = pd.Series(edstat_moment.loc[i,['ACS17 PhD','ACS16 PhD', \n",
    "       'ACS15 PhD', 'ACS14 PhD','ACS13 PhD', 'ACS12 PhD']])\n",
    "    m,b,r,p,std_err = stats.linregress(numbs.astype(float), testdata.astype(float))\n",
    "    results_HHPHD[i]=(m,b,r,p,std_err)\n",
    "\n",
    "len(results_HHPHD)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table B19054 (Interest, Dividends or Net Rental Income)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Income from interest, dividends or net rental income constitutes the bulk of noncapital returns from investment -- that is 'passive income'.  Table B19054 estimates whether during the preceding twelve month period the number of households that had, or did not have, any passive income.  The receipt of passive income may be a relevant factor in restaurant usage to the extent that it indicates that the household has invested wealth that might also support such usage.  That is, it is reasonable to assume that a household with investment income may partake of restaurants of the type considered here, while a household with no investment income probably would not partake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACS_list = [('ACS17_5YR_FULL_N',True),('ACS16_5YR_FULL_N',True),('ACS15_5YR_FULL_N',True),('ACS14_5YR_FULL_N',False),\n",
    "            ('ACS13_5YR_FULL_N',False),('ACS12_5YR_FULL_N',False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "B19054_current_fields = ['GEO.id2','HD01_VD01','HD01_VD02','HD01_VD03']\n",
    "current_names = ['Total','Passive Income','No Passive Iincome']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pds={}\n",
    "\n",
    "for i in range(len(ACS_list)):\n",
    "    subdir=ACS_list[i]\n",
    "# # #     print('subdir is: ', subdir)\n",
    "    tr = '/users/richardkornblith/Data_Science/NYCHR/Data_for_NYCHR/'+subdir[0]+'/'\n",
    "# #     print ('tr is: ', tr)\n",
    "    csv_file = fnmatch.filter(os.listdir(tr),'*054*with_ann.csv')\n",
    "#     print ('csv_file is: ', fnmatch)\n",
    "    full_path = tr+csv_file[0]\n",
    "#     print('full_path is: ', full_path)\n",
    "    cols = B19054_current_fields\n",
    "    col_names = current_names\n",
    "    df_t = pd.read_csv(full_path, index_col='GEO.id2',usecols=cols)\n",
    "#     print(df_t.info())\n",
    "    df_t.columns = [ACS_list[i][0][0:5]+\" \"+col_names[j] for j in range(len(col_names))]\n",
    "    df_t.drop(labels='Id2', inplace=True)\n",
    "    pds[ACS_list[i][0]]=df_t\n",
    "    \n",
    "# pds.items()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ACS17 Total', 'ACS17 Passive Income', 'ACS17 No Passive Iincome',\n",
       "       'ACS16 Total', 'ACS16 Passive Income', 'ACS16 No Passive Iincome',\n",
       "       'ACS15 Total', 'ACS15 Passive Income', 'ACS15 No Passive Iincome',\n",
       "       'ACS14 Total', 'ACS14 Passive Income', 'ACS14 No Passive Iincome',\n",
       "       'ACS13 Total', 'ACS13 Passive Income', 'ACS13 No Passive Iincome',\n",
       "       'ACS12 Total', 'ACS12 Passive Income', 'ACS12 No Passive Iincome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pincstat=pd.concat([pds[ACS_list[0][0]],pds[ACS_list[1][0]],pds[ACS_list[2][0]],pds[ACS_list[3][0]],pds[ACS_list[4][0]],pds[ACS_list[5][0]]],axis=1)\n",
    "pincstat_int=pincstat.astype(int)\n",
    "pincstat_int.head(10)\n",
    "pincstat_int.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 288 entries, 0 to 287\n",
      "Data columns (total 19 columns):\n",
      "GEO.id2                     288 non-null object\n",
      "ACS17 Total                 288 non-null int64\n",
      "ACS17 Passive Income        280 non-null float64\n",
      "ACS17 No Passive Iincome    280 non-null float64\n",
      "ACS16 Total                 288 non-null int64\n",
      "ACS16 Passive Income        280 non-null float64\n",
      "ACS16 No Passive Iincome    280 non-null float64\n",
      "ACS15 Total                 288 non-null int64\n",
      "ACS15 Passive Income        280 non-null float64\n",
      "ACS15 No Passive Iincome    280 non-null float64\n",
      "ACS14 Total                 288 non-null int64\n",
      "ACS14 Passive Income        279 non-null float64\n",
      "ACS14 No Passive Iincome    279 non-null float64\n",
      "ACS13 Total                 288 non-null int64\n",
      "ACS13 Passive Income        279 non-null float64\n",
      "ACS13 No Passive Iincome    279 non-null float64\n",
      "ACS12 Total                 288 non-null int64\n",
      "ACS12 Passive Income        279 non-null float64\n",
      "ACS12 No Passive Iincome    279 non-null float64\n",
      "dtypes: float64(12), int64(6), object(1)\n",
      "memory usage: 42.8+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 288 entries, 0 to 287\n",
      "Data columns (total 19 columns):\n",
      "GEO.id2                     288 non-null object\n",
      "ACS17 Total                 288 non-null int64\n",
      "ACS17 Passive Income        280 non-null float64\n",
      "ACS17 No Passive Iincome    280 non-null float64\n",
      "ACS16 Total                 288 non-null int64\n",
      "ACS16 Passive Income        280 non-null float64\n",
      "ACS16 No Passive Iincome    280 non-null float64\n",
      "ACS15 Total                 288 non-null int64\n",
      "ACS15 Passive Income        280 non-null float64\n",
      "ACS15 No Passive Iincome    280 non-null float64\n",
      "ACS14 Total                 288 non-null int64\n",
      "ACS14 Passive Income        279 non-null float64\n",
      "ACS14 No Passive Iincome    279 non-null float64\n",
      "ACS13 Total                 288 non-null int64\n",
      "ACS13 Passive Income        279 non-null float64\n",
      "ACS13 No Passive Iincome    279 non-null float64\n",
      "ACS12 Total                 288 non-null int64\n",
      "ACS12 Passive Income        279 non-null float64\n",
      "ACS12 No Passive Iincome    279 non-null float64\n",
      "dtypes: float64(12), int64(6), object(1)\n",
      "memory usage: 42.8+ KB\n"
     ]
    }
   ],
   "source": [
    "### Now we normalize the data by division of the number of households reporting a level of educational attainment of interest here \n",
    "# by the total number of households reporting educational attainment at any level in the respective surveys.  In the cases \n",
    "# where no households reported in\n",
    "# a particular survey, the resulting division by zero, resulting in a missing data 'NaN' entry, will be addressed below.\n",
    "\n",
    "pincstat_int['ACS17 Passive Income']= pincstat_int['ACS17 Passive Income'].div(pincstat_int['ACS17 Total'],axis=0)\n",
    "pincstat_int['ACS17 No Passive Iincome']= pincstat_int['ACS17 No Passive Iincome'].div(pincstat_int['ACS17 Total'],axis=0)\n",
    "pincstat_int['ACS16 Passive Income']= pincstat_int['ACS16 Passive Income'].div(pincstat_int['ACS16 Total'],axis=0)\n",
    "pincstat_int['ACS16 No Passive Iincome']= pincstat_int['ACS16 No Passive Iincome'].div(pincstat_int['ACS16 Total'],axis=0)\n",
    "pincstat_int['ACS15 Passive Income']= pincstat_int['ACS15 Passive Income'].div(pincstat_int['ACS15 Total'],axis=0)\n",
    "pincstat_int['ACS15 No Passive Iincome']= pincstat_int['ACS15 No Passive Iincome'].div(pincstat_int['ACS15 Total'],axis=0)\n",
    "pincstat_int['ACS14 Passive Income']= pincstat_int['ACS14 Passive Income'].div(pincstat_int['ACS14 Total'],axis=0)\n",
    "pincstat_int['ACS14 No Passive Iincome']= pincstat_int['ACS14 No Passive Iincome'].div(pincstat_int['ACS14 Total'],axis=0)\n",
    "pincstat_int['ACS13 Passive Income']= pincstat_int['ACS13 Passive Income'].div(pincstat_int['ACS13 Total'],axis=0)\n",
    "pincstat_int['ACS13 No Passive Iincome']= pincstat_int['ACS13 No Passive Iincome'].div(pincstat_int['ACS13 Total'],axis=0)\n",
    "pincstat_int['ACS12 Passive Income']= pincstat_int['ACS12 Passive Income'].div(pincstat_int['ACS12 Total'],axis=0)\n",
    "pincstat_int['ACS12 No Passive Iincome']= pincstat_int['ACS12 No Passive Iincome'].div(pincstat_int['ACS12 Total'],axis=0)\n",
    "\n",
    "pincstat_int_idx = pincstat_int.reset_index(level=0, inplace=False)\n",
    "pincstat_int_idx.info()\n",
    "# pincstat_int.head(10)\n",
    "# pincstat_int_idx.columns\n",
    "pincstat_int_idx.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Now we will address the missing data. We first will interpolate between valid data entries and after that we will try backfilling.\n",
    "# Any remaining instances that have missing data will be dropped.  \n",
    "# As will be seen, relatively few relevant census tracts are lost through this procedure:\n",
    " \n",
    "\n",
    "pincstat_int_clean= pd.DataFrame(pincstat_int_idx[['ACS17 Total', 'ACS17 Passive Income', 'ACS17 No Passive Iincome',\n",
    "       'ACS16 Total', 'ACS16 Passive Income', 'ACS16 No Passive Iincome',\n",
    "       'ACS15 Total', 'ACS15 Passive Income', 'ACS15 No Passive Iincome',\n",
    "       'ACS14 Total', 'ACS14 Passive Income', 'ACS14 No Passive Iincome',\n",
    "       'ACS13 Total', 'ACS13 Passive Income', 'ACS13 No Passive Iincome',\n",
    "       'ACS12 Total', 'ACS12 Passive Income', 'ACS12 No Passive Iincome']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 288 entries, 0 to 287\n",
      "Data columns (total 19 columns):\n",
      "ACS17 Total                 288 non-null float64\n",
      "ACS17 Passive Income        288 non-null float64\n",
      "ACS17 No Passive Iincome    288 non-null float64\n",
      "ACS16 Total                 288 non-null float64\n",
      "ACS16 Passive Income        288 non-null float64\n",
      "ACS16 No Passive Iincome    288 non-null float64\n",
      "ACS15 Total                 288 non-null float64\n",
      "ACS15 Passive Income        288 non-null float64\n",
      "ACS15 No Passive Iincome    288 non-null float64\n",
      "ACS14 Total                 288 non-null float64\n",
      "ACS14 Passive Income        288 non-null float64\n",
      "ACS14 No Passive Iincome    288 non-null float64\n",
      "ACS13 Total                 288 non-null float64\n",
      "ACS13 Passive Income        288 non-null float64\n",
      "ACS13 No Passive Iincome    288 non-null float64\n",
      "ACS12 Total                 288 non-null float64\n",
      "ACS12 Passive Income        288 non-null float64\n",
      "ACS12 No Passive Iincome    288 non-null float64\n",
      "Tract                       288 non-null object\n",
      "dtypes: float64(18), object(1)\n",
      "memory usage: 42.8+ KB\n"
     ]
    }
   ],
   "source": [
    "y=pincstat_int_clean.interpolate(method='linear',axis=1, inplace=False)\n",
    "z=y.fillna(method='bfill', axis=1)\n",
    "z['Tract']=pincstat_int_idx.loc[:,'GEO.id2']\n",
    "zz=z.dropna(axis=0)\n",
    "pincstat_moment = zz.reset_index(drop=True, inplace=False)\n",
    "pincstat_moment.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbs=pd.Series([0,1,2,3,4,5])\n",
    "# First, for Households Receiving Passive Income\n",
    "results_HHPINC = {}\n",
    "for i in range(len(pincstat_moment)):\n",
    "    testdata = pd.Series(pincstat_moment.loc[i,['ACS17 Passive Income','ACS16 Passive Income','ACS15 Passive Income',\n",
    "                                                'ACS14 Passive Income','ACS13 Passive Income','ACS12 Passive Income']])\n",
    "    m,b,r,p,std_err = stats.linregress(numbs.astype(float), testdata.astype(float))\n",
    "    results_HHPINC[i]=(m,b,r,p,std_err)\n",
    "len(results_HHPINC)\n",
    "\n",
    "\n",
    "# Now, for Households Receiving No Passive Income\n",
    "results_HHNPINC = {}\n",
    "for i in range(len(pincstat_moment)):\n",
    "    testdata = pd.Series(pincstat_moment.loc[i,['ACS17 No Passive Iincome','ACS16 No Passive Iincome', \n",
    "       'ACS15 No Passive Iincome', 'ACS14 No Passive Iincome','ACS13 No Passive Iincome', 'ACS12 No Passive Iincome']])\n",
    "    m,b,r,p,std_err = stats.linregress(numbs.astype(float), testdata.astype(float))\n",
    "    results_HHNPINC[i]=(m,b,r,p,std_err)\n",
    "len(results_HHNPINC)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table B19001 (Household Income in Past Twelve Months)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table B19001 estimates twelve-month household income by housing unit on the basis of income brackets ranging from under $10,000 to over $200,000.  It is likely that income level differentiation is relevant to the decision on whether to partake of restaurants of the type we envision.  For purposes of this study, we look to momentum in two brackets:  households with income of between $150,000 and $199,000; and households with income above that level.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACS_list = [('ACS17_5YR_FULL_N',True),('ACS16_5YR_FULL_N',True),('ACS15_5YR_FULL_N',True),('ACS14_5YR_FULL_N',False),\n",
    "            ('ACS13_5YR_FULL_N',False),('ACS12_5YR_FULL_N',False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Total', '150k-199k', '200k and Over']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B19001_current_fields = ['GEO.id2','HD01_VD01','HD01_VD16','HD01_VD17']\n",
    "current_names = ['Total','150k-199k','200k and Over']\n",
    "current_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pds={}\n",
    "\n",
    "for i in range(len(ACS_list)):\n",
    "    subdir=ACS_list[i]\n",
    "    tr = '/users/richardkornblith/Data_Science/NYCHR/Data_for_NYCHR/'+subdir[0]+'/'\n",
    "    csv_file = fnmatch.filter(os.listdir(tr),'*9001*with_ann.csv')\n",
    "    full_path = tr+csv_file[0]\n",
    "    cols = B19001_current_fields\n",
    "    col_names = current_names\n",
    "    df_t = pd.read_csv(full_path, index_col='GEO.id2',usecols=cols)\n",
    "    df_t.columns = [ACS_list[i][0][0:5]+\" \"+col_names[j] for j in range(len(col_names))]\n",
    "    df_t.drop(labels='Id2', inplace=True)\n",
    "    pds[ACS_list[i][0]]=df_t\n",
    "    \n",
    "# pds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 288 entries, 36061000100 to 36061031900\n",
      "Data columns (total 18 columns):\n",
      "ACS17 Total            288 non-null int64\n",
      "ACS17 150k-199k        288 non-null int64\n",
      "ACS17 200k and Over    288 non-null int64\n",
      "ACS16 Total            288 non-null int64\n",
      "ACS16 150k-199k        288 non-null int64\n",
      "ACS16 200k and Over    288 non-null int64\n",
      "ACS15 Total            288 non-null int64\n",
      "ACS15 150k-199k        288 non-null int64\n",
      "ACS15 200k and Over    288 non-null int64\n",
      "ACS14 Total            288 non-null int64\n",
      "ACS14 150k-199k        288 non-null int64\n",
      "ACS14 200k and Over    288 non-null int64\n",
      "ACS13 Total            288 non-null int64\n",
      "ACS13 150k-199k        288 non-null int64\n",
      "ACS13 200k and Over    288 non-null int64\n",
      "ACS12 Total            288 non-null int64\n",
      "ACS12 150k-199k        288 non-null int64\n",
      "ACS12 200k and Over    288 non-null int64\n",
      "dtypes: int64(18)\n",
      "memory usage: 42.8+ KB\n"
     ]
    }
   ],
   "source": [
    "gincstat=pd.concat([pds[ACS_list[0][0]],pds[ACS_list[1][0]],pds[ACS_list[2][0]],pds[ACS_list[3][0]],pds[ACS_list[4][0]],pds[ACS_list[5][0]]],axis=1)\n",
    "gincstat_int=gincstat.astype(int)\n",
    "gincstat_int.head(10)\n",
    "gincstat_int.columns\n",
    "gincstat_int.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 288 entries, 0 to 287\n",
      "Data columns (total 19 columns):\n",
      "GEO.id2                288 non-null object\n",
      "ACS17 Total            288 non-null int64\n",
      "ACS17 150k-199k        280 non-null float64\n",
      "ACS17 200k and Over    280 non-null float64\n",
      "ACS16 Total            288 non-null int64\n",
      "ACS16 150k-199k        280 non-null float64\n",
      "ACS16 200k and Over    280 non-null float64\n",
      "ACS15 Total            288 non-null int64\n",
      "ACS15 150k-199k        280 non-null float64\n",
      "ACS15 200k and Over    280 non-null float64\n",
      "ACS14 Total            288 non-null int64\n",
      "ACS14 150k-199k        279 non-null float64\n",
      "ACS14 200k and Over    279 non-null float64\n",
      "ACS13 Total            288 non-null int64\n",
      "ACS13 150k-199k        279 non-null float64\n",
      "ACS13 200k and Over    279 non-null float64\n",
      "ACS12 Total            288 non-null int64\n",
      "ACS12 150k-199k        279 non-null float64\n",
      "ACS12 200k and Over    279 non-null float64\n",
      "dtypes: float64(12), int64(6), object(1)\n",
      "memory usage: 42.8+ KB\n"
     ]
    }
   ],
   "source": [
    "### Now we normalize the data by division of the number of households reporting a level of educational attainment of interest here \n",
    "# by the total number of households reporting educational attainment at any level in the respective surveys.  In the cases \n",
    "# where no households reported in\n",
    "# a particular survey, the resulting division by zero, resulting in a missing data 'NaN' entry, will be addressed below.\n",
    "\n",
    "gincstat_int['ACS17 150k-199k']= gincstat_int['ACS17 150k-199k'].div(gincstat_int['ACS17 Total'],axis=0)\n",
    "gincstat_int['ACS17 200k and Over']= gincstat_int['ACS17 200k and Over'].div(gincstat_int['ACS17 Total'],axis=0)\n",
    "gincstat_int['ACS16 150k-199k']= gincstat_int['ACS16 150k-199k'].div(gincstat_int['ACS16 Total'],axis=0)\n",
    "gincstat_int['ACS16 200k and Over']= gincstat_int['ACS16 200k and Over'].div(gincstat_int['ACS16 Total'],axis=0)\n",
    "gincstat_int['ACS15 150k-199k']= gincstat_int['ACS15 150k-199k'].div(gincstat_int['ACS15 Total'],axis=0)\n",
    "gincstat_int['ACS15 200k and Over']= gincstat_int['ACS15 200k and Over'].div(gincstat_int['ACS15 Total'],axis=0)\n",
    "gincstat_int['ACS14 150k-199k']= gincstat_int['ACS14 150k-199k'].div(gincstat_int['ACS14 Total'],axis=0)\n",
    "gincstat_int['ACS14 200k and Over']= gincstat_int['ACS14 200k and Over'].div(gincstat_int['ACS14 Total'],axis=0)\n",
    "gincstat_int['ACS13 150k-199k']= gincstat_int['ACS13 150k-199k'].div(gincstat_int['ACS13 Total'],axis=0)\n",
    "gincstat_int['ACS13 200k and Over']= gincstat_int['ACS13 200k and Over'].div(gincstat_int['ACS13 Total'],axis=0)\n",
    "gincstat_int['ACS12 150k-199k']= gincstat_int['ACS12 150k-199k'].div(gincstat_int['ACS12 Total'],axis=0)\n",
    "gincstat_int['ACS12 200k and Over']= gincstat_int['ACS12 200k and Over'].div(gincstat_int['ACS12 Total'],axis=0)\n",
    "\n",
    "gincstat_int_idx = gincstat_int.reset_index(level=0, inplace=False)\n",
    "# gincstat_int.head(10)\n",
    "# gincstat_int_idx.columns\n",
    "gincstat_int_idx.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 280 entries, 0 to 279\n",
      "Data columns (total 13 columns):\n",
      "ACS17 150k-199k        280 non-null float64\n",
      "ACS17 200k and Over    280 non-null float64\n",
      "ACS16 150k-199k        280 non-null float64\n",
      "ACS16 200k and Over    280 non-null float64\n",
      "ACS15 150k-199k        280 non-null float64\n",
      "ACS15 200k and Over    280 non-null float64\n",
      "ACS14 150k-199k        280 non-null float64\n",
      "ACS14 200k and Over    280 non-null float64\n",
      "ACS13 150k-199k        280 non-null float64\n",
      "ACS13 200k and Over    280 non-null float64\n",
      "ACS12 150k-199k        280 non-null float64\n",
      "ACS12 200k and Over    280 non-null float64\n",
      "Tract                  280 non-null object\n",
      "dtypes: float64(12), object(1)\n",
      "memory usage: 28.5+ KB\n"
     ]
    }
   ],
   "source": [
    "##### Now we will address the missing data. We first will interpolate between valid data entries and after that we will try backfilling.\n",
    "# Any remaining instances that have missing data will be dropped.  \n",
    "# As will be seen, relatively few relevant census tracts are lost through this procedure:\n",
    " \n",
    "\n",
    "gincstat_int_clean= pd.DataFrame(gincstat_int_idx[['ACS17 150k-199k', 'ACS17 200k and Over','ACS16 150k-199k', 'ACS16 200k and Over',\n",
    "                                               'ACS15 150k-199k', 'ACS15 200k and Over','ACS14 150k-199k', 'ACS14 200k and Over',\n",
    "                                               'ACS13 150k-199k', 'ACS13 200k and Over','ACS12 150k-199k', 'ACS12 200k and Over']])\n",
    "y=gincstat_int_clean.interpolate(method='linear',axis=1, inplace=False)\n",
    "z=y.fillna(method='bfill', axis=1)\n",
    "z['Tract']=gincstat_int_idx.loc[:,'GEO.id2']\n",
    "zz=z.dropna(axis=0)\n",
    "gincstat_moment = zz.reset_index(drop=True, inplace=False)\n",
    "gincstat_moment.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbs=pd.Series([0,1,2,3,4,5])\n",
    "# First, for Households of 150k-199k Income\n",
    "results_HHMIDI = {}\n",
    "for i in range(len(gincstat_moment)):\n",
    "    testdata = pd.Series(gincstat_moment.loc[i,['ACS17 150k-199k','ACS16 150k-199k','ACS15 150k-199k', 'ACS14 150k-199k','ACS13 150k-199k',\n",
    "                                              'ACS12 150k-199k']])\n",
    "    m,b,r,p,std_err = stats.linregress(numbs.astype(float), testdata.astype(float))\n",
    "    results_HHMIDI[i]=(m,b,r,p,std_err)\n",
    "len(results_HHMIDI)\n",
    "\n",
    "\n",
    "# Now, for Households of 200k and over Income\n",
    "results_HHHII = {}\n",
    "for i in range(len(gincstat_moment)):\n",
    "    testdata = pd.Series(gincstat_moment.loc[i,['ACS17 200k and Over','ACS16 200k and Over', \n",
    "       'ACS15 200k and Over', 'ACS14 200k and Over','ACS13 200k and Over','ACS12 200k and Over']])\n",
    "    m,b,r,p,std_err = stats.linregress(numbs.astype(float), testdata.astype(float))\n",
    "    results_HHHII[i]=(m,b,r,p,std_err)\n",
    "len(results_HHHII)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
