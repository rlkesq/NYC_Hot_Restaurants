{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, fnmatch\n",
    "import matplotlib as mplt\n",
    "from scipy import stats\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Census Data\n",
    "\n",
    "### The United States Census Bureau (USCB) conducts the decennial 'census' required under the United States Constitution, but also conducts many other information gathering and desemination programs.  Indeed, nearly $100 billion of the federal budget is allocated among local geographical units, such as census tracts, based upon those surveys and estimates.  One of the most important such surveys is the American Community Survey (ACS), conducted annually and analyzed at different geographic levels on an annual basis and on a five-year basis projecting to the then current year based upon the annual surveys taken over the period.  The five-year ACS Surveys take the analysis down to the level of census tracts and, in most cases, block groups:  these surveys form the nucleus of the data for our analysis here.\n",
    "\n",
    "###  In this research, I am taking data from the five-year ACS Surveys for 2012 (i.e., providing data gathered from 2007-2012) through the 2017 five-year survey that was released in stages starting in November, 2018:  the 2017 ACS survey is the most recent comprehensive data for our purposes.  Of the thousands of tables included in the survey, I have winnowed the selection down to what I believe to be six particularly relevant features for our study of households, in each case evaluated at the tract level.  There are roughly 220 census tracts covering the island of Manhattan, of roughly equal population density: in midtown and downtown, each tract typically includes 15-20 blocks. \n",
    "\n",
    "### In its tables, the USCB distinguishes between family-based data and household-based data.  The latter looks particularly to the individuals living in a single housing unit, without necessary regard to any relationship among them.  More detail can be found regarding this concept and its consequences in the survey information published by the USCB.  In general, for some survey purposes that will be relevant here, the attributes of a \"housholder\" is studied: this references a leader in the housing unit without regard to whether that unit is a single family home or, as will be nearly universally the situation in cases in which we are interested here, an owned or leased condominium or coop unit. We will look in detail at that data, with regard to the number of occupants [Table B11001], the highest educational level achieved by the householder [Table B15003], the twelve-month household income [Table B19001], the receipt of any passive income (interest, dividends, rent) by the household [Table B19054], the age of the structure in which the household unit is situated [Table B25034], and the monthly rent asked of the household unit [Table B25061].\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Following my review of literature and experience in financing of economic development, my hypothesis is that successful rapid development of a restaurant-friendly neighborhood may be corollated with upward momentum in education, income, rents and investments of an upwardly mobile residential community.  The study of the census data is intended to provide a resource of features for our cluster analysis.  In this module, we will upload the data sets into Pandas dataframes, clean and normalize it, and then use a linear regression method to evaluate the upward (or downward) trend (or what I refer to as 'momentum') for each feature and on a census tract basis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading the Data\n",
    "\n",
    "#### We will be uploading five tables from each of six five-year surveys, referred to here as 'ACSnn_5YR' (referring to the nn-year American Communities five-year survey), into Pandas dataframes.  The raw data is located in the 'Data_for_NYCHR' that is part of the project repository.  The nomenclature also will refer to the specific tables (described above) from each survey.  All census data used here has been obtained from the USCB on its open-data website at: https://www.census.gov/acs/www/data/data-tables-and-tools/american-factfinder/.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current Rent Asked (Table B25061)\n",
    "\n",
    "### Unique to Table B25061, the table fields were modified by the USCB during the period of our study, to provide a more detailed differentiation of rents above $2,000/month.  That modification is reflected in the module below.  The fields of each of the other tables have remained consistent throughout the 2012-2017 releases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACS_list = [('ACS17_5YR_FULL_N',True),('ACS16_5YR_FULL_N',True),('ACS15_5YR_FULL_N',True),('ACS14_5YR_FULL_N',False),\n",
    "            ('ACS13_5YR_FULL_N',False),('ACS12_5YR_FULL_N',False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "B25061_current_fields = ['GEO.id2','HD01_VD01','HD01_VD22','HD01_VD23','HD01_VD24','HD01_VD25']\n",
    "current_names = ['Total','>$2,000','>$2,500','>$3,000','>$3,500']\n",
    "B25061_original_fields = ['GEO.id2','HD01_VD01','HD01_VD22']\n",
    "original_names = ['Total','>$2,000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pds={}\n",
    "\n",
    "for i in range(len(ACS_list)):\n",
    "    subdir=ACS_list[i]\n",
    "    tr = '/users/richardkornblith/Data_Science/NYCHR/Data_for_NYCHR/'+subdir[0]+'/'\n",
    "    csv_file = fnmatch.filter(os.listdir(tr),'*61*with_ann.csv')\n",
    "    full_path = tr+csv_file[0]\n",
    "    if ACS_list[i][1]:\n",
    "        cols = B25061_current_fields\n",
    "        col_names = current_names\n",
    "    else:\n",
    "        cols = B25061_original_fields\n",
    "        col_names = original_names\n",
    "    df_t = pd.read_csv(full_path, index_col='GEO.id2',usecols=cols)\n",
    "    df_t.columns = [ACS_list[i][0][0:5]+\" \"+col_names[j] for j in range(len(col_names))]\n",
    "    df_t.drop(labels='Id2', inplace=True)\n",
    "    pds[ACS_list[i][0]]=df_t\n",
    "# pds['ACS17_5YR_FULL_N'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ACS17 Total', 'ACS17 >$2,000', 'ACS17 >$2,500', 'ACS17 >$3,000',\n",
       "       'ACS17 >$3,500', 'ACS16 Total', 'ACS16 >$2,000', 'ACS16 >$2,500',\n",
       "       'ACS16 >$3,000', 'ACS16 >$3,500', 'ACS15 Total', 'ACS15 >$2,000',\n",
       "       'ACS15 >$2,500', 'ACS15 >$3,000', 'ACS15 >$3,500', 'ACS14 Total',\n",
       "       'ACS14 >$2,000', 'ACS13 Total', 'ACS13 >$2,000', 'ACS12 Total',\n",
       "       'ACS12 >$2,000'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rentstat=pd.concat([pds[ACS_list[0][0]],pds[ACS_list[1][0]],pds[ACS_list[2][0]],pds[ACS_list[3][0]],pds[ACS_list[4][0]],pds[ACS_list[5][0]]],axis=1)\n",
    "rentstat.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 288 entries, 36061000100 to 36061031900\n",
      "Data columns (total 15 columns):\n",
      "ACS17 >$3,500    252 non-null float64\n",
      "ACS17 >$3,000    252 non-null float64\n",
      "ACS17 >$2,500    254 non-null float64\n",
      "ACS17 >$2,000    251 non-null float64\n",
      "ACS16 >$3,500    252 non-null float64\n",
      "ACS16 >$3,000    255 non-null float64\n",
      "ACS16 >$2,500    251 non-null float64\n",
      "ACS16 >$2,000    251 non-null float64\n",
      "ACS15 >$3,500    252 non-null float64\n",
      "ACS15 >$3,000    256 non-null float64\n",
      "ACS15 >$2,500    252 non-null float64\n",
      "ACS15 >$2,000    252 non-null float64\n",
      "ACS14 >$2,000    256 non-null float64\n",
      "ACS13 >$2,000    259 non-null float64\n",
      "ACS12 >$2,000    260 non-null float64\n",
      "dtypes: float64(15)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "### Now we normalize the data by division of the number of households reporting a level of educational attainment of interest here \n",
    "# by the total number of households reporting educational attainment at any level in the respective surveys.  In the cases \n",
    "# where no households reported in\n",
    "# a particular survey, the resulting division by zero, resulting in a missing data 'NaN' entry, will be addressed below.\n",
    "\n",
    "rentstat_n=pd.DataFrame()\n",
    "\n",
    "rentstat['ACS17 Total'] = rentstat['ACS17 Total'].astype(float)\n",
    "rentstat['ACS16 Total'] = rentstat['ACS16 Total'].astype(float)\n",
    "rentstat['ACS15 Total'] = rentstat['ACS15 Total'].astype(float)\n",
    "rentstat['ACS14 Total'] = rentstat['ACS14 Total'].astype(float)\n",
    "rentstat['ACS13 Total'] = rentstat['ACS13 Total'].astype(float)\n",
    "rentstat['ACS12 Total'] = rentstat['ACS12 Total'].astype(float)\n",
    "\n",
    "\n",
    "rentstat['ACS17 >$3,500'] = rentstat['ACS17 >$3,500'].astype(float)\n",
    "rentstat['ACS17 >$3,000'] = rentstat['ACS17 >$3,000'].astype(float)\n",
    "rentstat['ACS17 >$2,500'] = rentstat['ACS17 >$2,500'].astype(float)\n",
    "rentstat['ACS17 >$2,000'] = rentstat['ACS17 >$2,000'].astype(float)\n",
    "rentstat['ACS16 >$3,500'] = rentstat['ACS16 >$3,500'].astype(float)\n",
    "rentstat['ACS16 >$3,000'] = rentstat['ACS16 >$3,000'].astype(float)\n",
    "rentstat['ACS16 >$2,500'] = rentstat['ACS16 >$2,500'].astype(float)\n",
    "rentstat['ACS16 >$2,000'] = rentstat['ACS16 >$2,000'].astype(float)\n",
    "rentstat['ACS15 >$3,500'] = rentstat['ACS15 >$3,500'].astype(float)\n",
    "rentstat['ACS15 >$3,000'] = rentstat['ACS15 >$3,000'].astype(float)\n",
    "rentstat['ACS15 >$2,500'] = rentstat['ACS15 >$2,500'].astype(float)\n",
    "rentstat['ACS15 >$2,000'] = rentstat['ACS15 >$2,000'].astype(float)\n",
    "rentstat['ACS14 >$2,000'] = rentstat['ACS14 >$2,000'].astype(float)\n",
    "rentstat['ACS13 >$2,000'] = rentstat['ACS13 >$2,000'].astype(float)\n",
    "rentstat['ACS12 >$2,000'] = rentstat['ACS12 >$2,000'].astype(float)\n",
    "\n",
    "\n",
    "rentstat_n['ACS17 >$3,500'] = rentstat['ACS17 >$3,500'].div(rentstat['ACS17 Total'])\n",
    "rentstat_n['ACS17 >$3,000'] = rentstat['ACS17 >$3,000'].div(rentstat['ACS17 Total'])\n",
    "rentstat_n['ACS17 >$2,500'] = rentstat['ACS17 >$2,500'].div(rentstat['ACS16 Total'])\n",
    "rentstat_n['ACS17 >$2,000'] = rentstat['ACS17 >$2,000'].div(rentstat['ACS16 Total'])\n",
    "rentstat_n['ACS16 >$3,500'] = rentstat['ACS16 >$3,500'].div(rentstat['ACS17 Total'])\n",
    "rentstat_n['ACS16 >$3,000'] = rentstat['ACS16 >$3,000'].div(rentstat['ACS17 Total'])\n",
    "rentstat_n['ACS16 >$2,500'] = rentstat['ACS16 >$2,500'].div(rentstat['ACS16 Total'])\n",
    "rentstat_n['ACS16 >$2,000'] = rentstat['ACS16 >$2,000'].div(rentstat['ACS16 Total'])\n",
    "rentstat_n['ACS15 >$3,500'] = rentstat['ACS15 >$3,500'].div(rentstat['ACS17 Total'])\n",
    "rentstat_n['ACS15 >$3,000'] = rentstat['ACS15 >$3,000'].div(rentstat['ACS17 Total'])\n",
    "rentstat_n['ACS15 >$2,500'] = rentstat['ACS15 >$2,500'].div(rentstat['ACS16 Total'])\n",
    "rentstat_n['ACS15 >$2,000'] = rentstat['ACS15 >$2,000'].div(rentstat['ACS16 Total'])\n",
    "rentstat_n['ACS14 >$2,000'] = rentstat['ACS14 >$2,000'].div(rentstat['ACS16 Total'])\n",
    "rentstat_n['ACS13 >$2,000'] = rentstat['ACS13 >$2,000'].div(rentstat['ACS16 Total'])\n",
    "rentstat_n['ACS12 >$2,000'] = rentstat['ACS12 >$2,000'].div(rentstat['ACS16 Total'])\n",
    "\n",
    "\n",
    "rentstat_n.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ACS17 >$3,500', 'ACS17 >$3,000', 'ACS17 >$2,500', 'ACS17 >$2,000',\n",
       "       'ACS16 >$3,500', 'ACS16 >$3,000', 'ACS16 >$2,500', 'ACS16 >$2,000',\n",
       "       'ACS15 >$3,500', 'ACS15 >$3,000', 'ACS15 >$2,500', 'ACS15 >$2,000',\n",
       "       'ACS14 >$2,000', 'ACS13 >$2,000', 'ACS12 >$2,000', 'Tract'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we will address the missing data. We first will interpolate between valid data entries and after that we will try backfilling.\n",
    "# Any remaining instances that have missing data (np.inf or NaN) will be dropped. We will be careful to maintain the mapping of indices to\n",
    "# census tracts\n",
    " \n",
    "rentstat_int = rentstat_n.reset_index(drop=False, inplace=False)\n",
    "rentstat_int_clean = pd.DataFrame(rentstat_int[['ACS17 >$3,500', 'ACS17 >$3,000', 'ACS17 >$2,500', 'ACS17 >$2,000','ACS16 >$3,500', 'ACS16 >$3,000', 'ACS16 >$2,500', 'ACS16 >$2,000',\n",
    "                                               'ACS15 >$3,500', 'ACS15 >$3,000', 'ACS15 >$2,500', 'ACS15 >$2,000','ACS14 >$2,000', 'ACS13 >$2,000', 'ACS12 >$2,000']])\n",
    "y=rentstat_int_clean.interpolate(method='linear',axis=1, inplace=False)\n",
    "\n",
    "z=y.fillna(method='bfill', axis=1)\n",
    "z['Tract'] = rentstat_int['GEO.id2']\n",
    "zz = z.dropna(axis=0)\n",
    "zz = zz.replace(np.inf, np.nan)\n",
    "zz = zz.dropna()\n",
    "\n",
    "rentstat_moment = zz\n",
    "rentstat_moment = zz.reset_index(drop=True, inplace=False)\n",
    "rentstat_moment.columns\n",
    "# rentstat_moment.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will determine the momentum of the population of households on each feature by taking a straight line linear regression of the six years of data sets.  As an aside, there nearly certainly are more available, but complex, methods for measuring this momentum: however, the scipy stats.linregress method should provide adequate trend information and statistical analysis for out purposes.  Here, we create a dictionary of results, one entry for each census tract that had valid data: the values in each entry are the slope (m) and the intercept (b) for the line, and the correlation factor (r), p-value (p) and standard error (std_err) for the fit to the data.  A cursory review of the results reveals a wide dispersion in slopes (momentum), with remarkably strong statistics. This is reassuring, as the principal reason for including as many as six data points for each tract was to reduce the impact of statistical noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this and the corresponding portions of this notebook, we will be evaluating the linear regression on each feature.\n",
    "\n",
    "numbs=pd.Series([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14])\n",
    "results_rents = {}\n",
    "for i in range(len(rentstat_moment)):\n",
    "    testdata = pd.Series(rentstat_moment.loc[i,['ACS17 >$3,500', 'ACS17 >$3,000', 'ACS17 >$2,500', 'ACS17 >$2,000',\n",
    "       'ACS16 >$3,500', 'ACS16 >$3,000', 'ACS16 >$2,500', 'ACS16 >$2,000',\n",
    "       'ACS15 >$3,500', 'ACS15 >$3,000', 'ACS15 >$2,500', 'ACS15 >$2,000',\n",
    "       'ACS14 >$2,000', 'ACS13 >$2,000', 'ACS12 >$2,000']])\n",
    "    m,b,r,p,std_err = stats.linregress(numbs.astype(float), testdata.astype(float))\n",
    "    results_rents[i]=(m,b,r,p,std_err)\n",
    "\n",
    "# results_rents[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 250 entries, 0 to 249\n",
      "Data columns (total 2 columns):\n",
      "0         250 non-null float64\n",
      "Tracts    250 non-null object\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 5.9+ KB\n"
     ]
    }
   ],
   "source": [
    "RENTS_k = pd.DataFrame(results_rents).T\n",
    "RENTS_k['Tracts'] = rentstat_moment['Tract']\n",
    "RENTS_k.drop(labels=[1,2,3,4], axis=1, inplace=True)\n",
    "RENTS_k.rename(columns = {0:'rent_m'})\n",
    "RENTS_k.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "RENTS_k.to_csv('/users/richardkornblith/Data_Science/NYCHR/Data_for_NYCHR/RENTS_k.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading and Analyzing the Remaining Feature Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table B11001 (Household Type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table B11001 addresses the composition of the members of a household unit.  It discriminates between households comprising two or more members of a 'family' and those comprising one or more persons who are not of the same family; within the latter group, separate features include households of a persons living alone, on the one hand, and those of two or more persons. For purposes of our study, I have included only the latter two features since (i) the category of family households is the converse of the category of total nonfamily households (given the total number of responses); (ii) in the case of units occupied by families, no distinction is made between those with and those without children of a young age that might be relevant to decisions regarding dining at restaurants of the type contemplated in this study; but (iii) it is resonable to expect that the restaurant behavior of households comprising only one person would be different from that of households comprising two or more unrelated persons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the avoidance of confusion, we will continue to use the ACS_list of tuples, notwithstanding that the second member of each tuple was\n",
    "# introduced solely to accommodate the change in fields on B25061, discussed above.\n",
    "\n",
    "ACS_list = [('ACS17_5YR_FULL_N',True),('ACS16_5YR_FULL_N',True),('ACS15_5YR_FULL_N',True),('ACS14_5YR_FULL_N',False),\n",
    "            ('ACS13_5YR_FULL_N',False),('ACS12_5YR_FULL_N',False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "B11001_current_fields = ['GEO.id2','HD01_VD01','HD01_VD08','HD01_VD09']\n",
    "current_names = ['Total','HH Living Alone','HH Not Living Alone']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pds={}\n",
    "\n",
    "for i in range(len(ACS_list)):\n",
    "    subdir=ACS_list[i]\n",
    "    tr = '/users/richardkornblith/Data_Science/NYCHR/Data_for_NYCHR/'+subdir[0]+'/'\n",
    "    csv_file = fnmatch.filter(os.listdir(tr),'*01*with_ann.csv')\n",
    "    full_path = tr+csv_file[0]\n",
    "    cols = B11001_current_fields\n",
    "    col_names = current_names\n",
    "    df_t = pd.read_csv(full_path, index_col='GEO.id2',usecols=cols)\n",
    "    df_t.columns = [ACS_list[i][0][0:5]+\" \"+col_names[j] for j in range(len(col_names))]\n",
    "    df_t.drop(labels='Id2', inplace=True)\n",
    "    pds[ACS_list[i][0]]=df_t\n",
    "    \n",
    "# pds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hhstat=pd.concat([pds[ACS_list[0][0]],pds[ACS_list[1][0]],pds[ACS_list[2][0]],pds[ACS_list[3][0]],pds[ACS_list[4][0]],pds[ACS_list[5][0]]],axis=1)\n",
    "hhstat_int=hhstat.astype(int)\n",
    "# hhstat_int.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now we normalize the data by division of the number of households reporting occupancy status  \n",
    "# by the total number of households reporting rent in the respective surveys.  In the cases where no households reported in\n",
    "# a particular survey, the resulting division by zero, resulting in a missing data 'NaN' entry, will be addressed below.\n",
    "\n",
    "hhstat_n=pd.DataFrame()\n",
    "\n",
    "hhstat['ACS17 Total'] = hhstat['ACS17 Total'].astype(float)\n",
    "hhstat['ACS16 Total'] = hhstat['ACS16 Total'].astype(float)\n",
    "hhstat['ACS15 Total'] = hhstat['ACS15 Total'].astype(float)\n",
    "hhstat['ACS14 Total'] = hhstat['ACS14 Total'].astype(float)\n",
    "hhstat['ACS13 Total'] = hhstat['ACS13 Total'].astype(float)\n",
    "hhstat['ACS12 Total'] = hhstat['ACS12 Total'].astype(float)\n",
    "\n",
    "hhstat['ACS17 HH Living Alone'] = hhstat['ACS17 HH Living Alone'].astype(float)\n",
    "hhstat['ACS17 HH Not Living Alone'] = hhstat['ACS17 HH Not Living Alone'].astype(float)\n",
    "hhstat['ACS16 HH Living Alone'] = hhstat['ACS16 HH Living Alone'].astype(float)\n",
    "hhstat['ACS16 HH Not Living Alone'] = hhstat['ACS16 HH Not Living Alone'].astype(float)\n",
    "hhstat['ACS15 HH Living Alone'] = hhstat['ACS15 HH Living Alone'].astype(float)\n",
    "hhstat['ACS15 HH Not Living Alone'] = hhstat['ACS15 HH Not Living Alone'].astype(float)\n",
    "hhstat['ACS14 HH Living Alone'] = hhstat['ACS14 HH Living Alone'].astype(float)\n",
    "hhstat['ACS14 HH Not Living Alone'] = hhstat['ACS14 HH Not Living Alone'].astype(float)\n",
    "hhstat['ACS13 HH Living Alone'] = hhstat['ACS13 HH Living Alone'].astype(float)\n",
    "hhstat['ACS13 HH Not Living Alone'] = hhstat['ACS13 HH Not Living Alone'].astype(float)\n",
    "hhstat['ACS12 HH Living Alone'] = hhstat['ACS12 HH Living Alone'].astype(float)\n",
    "hhstat['ACS12 HH Not Living Alone'] = hhstat['ACS12 HH Not Living Alone'].astype(float)\n",
    "\n",
    "hhstat_n['ACS17 HH Living Alone'] = hhstat['ACS17 HH Living Alone'].div(hhstat['ACS17 Total'])\n",
    "hhstat_n['ACS17 HH Not Living Alone'] = hhstat['ACS17 HH Not Living Alone'].div(hhstat['ACS17 Total'])\n",
    "hhstat_n['ACS16 HH Living Alone'] = hhstat['ACS16 HH Living Alone'].div(hhstat['ACS16 Total'])\n",
    "hhstat_n['ACS16 HH Not Living Alone'] = hhstat['ACS16 HH Not Living Alone'].div(hhstat['ACS16 Total'])\n",
    "hhstat_n['ACS15 HH Living Alone'] = hhstat['ACS15 HH Living Alone'].div(hhstat['ACS15 Total'])\n",
    "hhstat_n['ACS15 HH Not Living Alone'] = hhstat['ACS15 HH Not Living Alone'].div(hhstat['ACS15 Total'])\n",
    "hhstat_n['ACS14 HH Living Alone'] = hhstat['ACS14 HH Living Alone'].div(hhstat['ACS14 Total'])\n",
    "hhstat_n['ACS14 HH Not Living Alone'] = hhstat['ACS14 HH Not Living Alone'].div(hhstat['ACS14 Total'])\n",
    "hhstat_n['ACS13 HH Living Alone'] = hhstat['ACS13 HH Living Alone'].div(hhstat['ACS13 Total'])\n",
    "hhstat_n['ACS13 HH Not Living Alone'] = hhstat['ACS13 HH Not Living Alone'].div(hhstat['ACS13 Total'])\n",
    "hhstat_n['ACS12 HH Living Alone'] = hhstat['ACS12 HH Living Alone'].div(hhstat['ACS12 Total'])\n",
    "hhstat_n['ACS12 HH Not Living Alone'] = hhstat['ACS12 HH Not Living Alone'].div(hhstat['ACS12 Total'])\n",
    "\n",
    "\n",
    "# hhstat_int.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will address the missing data. We first will interpolate between valid data entries and after that we will try backfilling.\n",
    "# Any remaining instances that have missing data (np.inf or NaN) will be dropped. We will be careful to maintain the mapping of indices to\n",
    "# census tracts\n",
    " \n",
    "hhstat_int = hhstat_n.reset_index(drop=False, inplace=False)\n",
    "hhstat_int_clean= pd.DataFrame(hhstat_int[['ACS17 HH Living Alone', 'ACS17 HH Not Living Alone',\n",
    "       'ACS16 HH Living Alone', 'ACS16 HH Not Living Alone',\n",
    "       'ACS15 HH Living Alone', 'ACS15 HH Not Living Alone',\n",
    "       'ACS14 HH Living Alone', 'ACS14 HH Not Living Alone',\n",
    "       'ACS13 HH Living Alone', 'ACS13 HH Not Living Alone',\n",
    "       'ACS12 HH Living Alone', 'ACS12 HH Not Living Alone']])\n",
    "y=hhstat_int_clean.interpolate(method='linear',axis=1, inplace=False)\n",
    "z=y.fillna(method='bfill', axis=1)\n",
    "\n",
    "z['Tract']=hhstat_int.loc[:,'GEO.id2']\n",
    "\n",
    "zz=z.dropna(axis=0)\n",
    "zz = zz.replace(np.inf, np.nan)\n",
    "zz = zz.dropna()\n",
    "\n",
    "hhstat_moment = zz.reset_index(drop=True, inplace=False)\n",
    "# hhstat_moment.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbs=pd.Series([0,1,2,3,4,5])\n",
    "# First, for Households Living Alone\n",
    "results_HHLA = {}\n",
    "for i in range(len(hhstat_moment)):\n",
    "    testdata = pd.Series(hhstat_moment.loc[i,['ACS17 HH Living Alone','ACS16 HH Living Alone', \n",
    "       'ACS15 HH Living Alone', 'ACS14 HH Living Alone','ACS13 HH Living Alone', 'ACS12 HH Living Alone']])\n",
    "    m,b,r,p,std_err = stats.linregress(numbs.astype(float), testdata.astype(float))\n",
    "    results_HHLA[i]=(m,b,r,p,std_err)\n",
    "len(results_HHLA)\n",
    "\n",
    "\n",
    "# Now, for Households Not Living Alone\n",
    "results_HHNLA = {}\n",
    "for i in range(len(hhstat_moment)):\n",
    "    testdata = pd.Series(hhstat_moment.loc[i,['ACS17 HH Living Alone','ACS16 HH Living Alone', \n",
    "       'ACS15 HH Living Alone', 'ACS14 HH Living Alone','ACS13 HH Living Alone', 'ACS12 HH Living Alone']])\n",
    "    m,b,r,p,std_err = stats.linregress(numbs.astype(float), testdata.astype(float))\n",
    "    results_HHNLA[i]=(m,b,r,p,std_err)\n",
    "# len(results_HHNLA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "HHLA_k = pd.DataFrame(results_HHLA).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 280 entries, 0 to 279\n",
      "Data columns (total 2 columns):\n",
      "0         280 non-null float64\n",
      "Tracts    280 non-null object\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 6.6+ KB\n"
     ]
    }
   ],
   "source": [
    "HHLA_k['Tracts'] = hhstat_moment['Tract']\n",
    "HHLA_k.drop(labels=[1,2,3,4], axis=1, inplace=True)\n",
    "HHLA_k.rename(columns = {0:'rent_m'})\n",
    "HHLA_k.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "HHLA_k.to_csv('/users/richardkornblith/Data_Science/NYCHR/Data_for_NYCHR/HHLA_k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 280 entries, 0 to 279\n",
      "Data columns (total 2 columns):\n",
      "0         280 non-null float64\n",
      "Tracts    280 non-null object\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 6.6+ KB\n"
     ]
    }
   ],
   "source": [
    "HHNLA_k = pd.DataFrame(results_HHNLA).T\n",
    "HHNLA_k['Tracts'] = hhstat_moment['Tract']\n",
    "HHNLA_k.drop(labels=[1,2,3,4], axis=1, inplace=True)\n",
    "HHNLA_k.rename(columns = {0:'HHNLA_m'})\n",
    "HHNLA_k.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "HHNLA_k.to_csv('/users/richardkornblith/Data_Science/NYCHR/Data_for_NYCHR/HHNLA_k.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table B15003 (Educational Attainment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table B15003 addresses the highest level of educational attainment in the household. It provides very detailed classifications of such attainment, from lower school through the Ph.D. level.  In my experience (having both a J.D. and a Ph.D.), the restaurant choices made by persons holding a Masters or lower level of attainment is quite different from that of a holder of a professional degree, and each of those is very different from the decisions made by a holder of a Ph.D. This study will utilize as features only the three highest levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACS_list = [('ACS17_5YR_FULL_N',True),('ACS16_5YR_FULL_N',True),('ACS15_5YR_FULL_N',True),('ACS14_5YR_FULL_N',False),\n",
    "            ('ACS13_5YR_FULL_N',False),('ACS12_5YR_FULL_N',False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GEO.id2', 'HD01_VD01', 'HD01_VD23', 'HD01_VD24', 'HD01_VD25']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B15003_current_fields = ['GEO.id2','HD01_VD01','HD01_VD23','HD01_VD24','HD01_VD25']\n",
    "current_names = ['Total','Masters','Professional', 'PhD']\n",
    "B15003_current_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pds={}\n",
    "\n",
    "for i in range(len(ACS_list)):\n",
    "    subdir=ACS_list[i]\n",
    "    tr = '/users/richardkornblith/Data_Science/NYCHR/Data_for_NYCHR/'+subdir[0]+'/'\n",
    "    csv_file = fnmatch.filter(os.listdir(tr),'*003*with_ann.csv')\n",
    "    full_path = tr+csv_file[0]\n",
    "    cols = B15003_current_fields\n",
    "    col_names = current_names\n",
    "    df_t = pd.read_csv(full_path, index_col='GEO.id2',usecols=cols)\n",
    "    df_t.columns = [ACS_list[i][0][0:5]+\" \"+col_names[j] for j in range(len(col_names))]\n",
    "    df_t.drop(labels='Id2', inplace=True)\n",
    "    pds[ACS_list[i][0]]=df_t\n",
    "    \n",
    "# pds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ACS17 Total', 'ACS17 Masters', 'ACS17 Professional', 'ACS17 PhD',\n",
       "       'ACS16 Total', 'ACS16 Masters', 'ACS16 Professional', 'ACS16 PhD',\n",
       "       'ACS15 Total', 'ACS15 Masters', 'ACS15 Professional', 'ACS15 PhD',\n",
       "       'ACS14 Total', 'ACS14 Masters', 'ACS14 Professional', 'ACS14 PhD',\n",
       "       'ACS13 Total', 'ACS13 Masters', 'ACS13 Professional', 'ACS13 PhD',\n",
       "       'ACS12 Total', 'ACS12 Masters', 'ACS12 Professional', 'ACS12 PhD'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edstat=pd.concat([pds[ACS_list[0][0]],pds[ACS_list[1][0]],pds[ACS_list[2][0]],pds[ACS_list[3][0]],pds[ACS_list[4][0]],pds[ACS_list[5][0]]],axis=1)\n",
    "edstat.columns\n",
    "# edstat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now we normalize the data by division of the number of households reporting a level of educational attainment of interest here \n",
    "# by the total number of households reporting educational attainment at any level in the respective surveys.  In the cases \n",
    "# where no households reported in\n",
    "# a particular survey, the resulting division by zero, resulting in a missing data 'NaN' entry, will be addressed below.\n",
    "\n",
    "\n",
    "edstat_n=pd.DataFrame()\n",
    "\n",
    "edstat['ACS17 Total'] = edstat['ACS17 Total'].astype(float)\n",
    "edstat['ACS16 Total'] = edstat['ACS16 Total'].astype(float)\n",
    "edstat['ACS15 Total'] = edstat['ACS15 Total'].astype(float)\n",
    "edstat['ACS14 Total'] = edstat['ACS14 Total'].astype(float)\n",
    "edstat['ACS13 Total'] = edstat['ACS13 Total'].astype(float)\n",
    "edstat['ACS12 Total'] = edstat['ACS12 Total'].astype(float)\n",
    "\n",
    "edstat['ACS17 Masters'] = edstat['ACS17 Masters'].astype(float)\n",
    "edstat['ACS17 Professional'] = edstat['ACS17 Professional'].astype(float)\n",
    "edstat['ACS17 PhD'] = edstat['ACS17 PhD'].astype(float)\n",
    "edstat['ACS16 Masters'] = edstat['ACS16 Masters'].astype(float)\n",
    "edstat['ACS16 Professional'] = edstat['ACS16 Professional'].astype(float)\n",
    "edstat['ACS16 PhD'] = edstat['ACS16 PhD'].astype(float)\n",
    "edstat['ACS15 Masters'] = edstat['ACS15 Masters'].astype(float)\n",
    "edstat['ACS15 Professional'] = edstat['ACS15 Professional'].astype(float)\n",
    "edstat['ACS15 PhD'] = edstat['ACS15 PhD'].astype(float)\n",
    "edstat['ACS14 Masters'] = edstat['ACS14 Masters'].astype(float)\n",
    "edstat['ACS14 Professional'] = edstat['ACS14 Professional'].astype(float)\n",
    "edstat['ACS14 PhD'] = edstat['ACS14 PhD'].astype(float)\n",
    "edstat['ACS13 Masters'] = edstat['ACS13 Masters'].astype(float)\n",
    "edstat['ACS13 Professional'] = edstat['ACS13 Professional'].astype(float)\n",
    "edstat['ACS13 PhD'] = edstat['ACS13 PhD'].astype(float)\n",
    "edstat['ACS12 Masters'] = edstat['ACS12 Masters'].astype(float)\n",
    "edstat['ACS12 Professional'] = edstat['ACS12 Professional'].astype(float)\n",
    "edstat['ACS12 PhD'] = edstat['ACS12 PhD'].astype(float)\n",
    "\n",
    "\n",
    "edstat_n['ACS17 Masters'] = edstat['ACS17 Masters'].div(edstat['ACS17 Total'])\n",
    "edstat_n['ACS17 Professional'] = edstat['ACS17 Professional'].div(edstat['ACS17 Total'])\n",
    "edstat_n['ACS17 PhD'] = edstat['ACS17 PhD'].div(edstat['ACS17 Total'])\n",
    "edstat_n['ACS16 Masters'] = edstat['ACS16 Masters'].div(edstat['ACS16 Total'])\n",
    "edstat_n['ACS16 Professional'] = edstat['ACS16 Professional'].div(edstat['ACS16 Total'])\n",
    "edstat_n['ACS16 PhD'] = edstat['ACS16 PhD'].div(edstat['ACS16 Total'])\n",
    "edstat_n['ACS15 Masters'] = edstat['ACS17 Masters'].div(edstat['ACS15 Total'])\n",
    "edstat_n['ACS15 Professional'] = edstat['ACS15 Professional'].div(edstat['ACS15 Total'])\n",
    "edstat_n['ACS15 PhD'] = edstat['ACS15 PhD'].div(edstat['ACS15 Total'])\n",
    "edstat_n['ACS14 Masters'] = edstat['ACS17 Masters'].div(edstat['ACS14 Total'])\n",
    "edstat_n['ACS14 Professional'] = edstat['ACS14 Professional'].div(edstat['ACS14 Total'])\n",
    "edstat_n['ACS14 PhD'] = edstat['ACS14 PhD'].div(edstat['ACS14 Total'])\n",
    "edstat_n['ACS13 Masters'] = edstat['ACS17 Masters'].div(edstat['ACS13 Total'])\n",
    "edstat_n['ACS13 Professional'] = edstat['ACS13 Professional'].div(edstat['ACS13 Total'])\n",
    "edstat_n['ACS13 PhD'] = edstat['ACS13 PhD'].div(edstat['ACS13 Total'])\n",
    "edstat_n['ACS12 Masters'] = edstat['ACS17 Masters'].div(edstat['ACS12 Total'])\n",
    "edstat_n['ACS12 Professional'] = edstat['ACS12 Professional'].div(edstat['ACS12 Total'])\n",
    "edstat_n['ACS12 PhD'] = edstat['ACS12 PhD'].div(edstat['ACS12 Total'])\n",
    "\n",
    "\n",
    "# edstat_int_idx.info()\n",
    "# edstat_int.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will address the missing data. We first will interpolate between valid data entries and after that we will try backfilling.\n",
    "# Any remaining instances that have missing data (np.inf or NaN) will be dropped. We will be careful to maintain the mapping of indices to\n",
    "# census tracts:\n",
    " \n",
    "edstat_int=edstat_n.reset_index(drop=False, inplace=False)\n",
    "\n",
    "edstat_int_clean= pd.DataFrame(edstat_int[['ACS17 Masters', 'ACS17 Professional', 'ACS17 PhD',\n",
    "       'ACS16 Masters', 'ACS16 Professional', 'ACS16 PhD',\n",
    "       'ACS15 Masters', 'ACS15 Professional', 'ACS15 PhD',\n",
    "       'ACS14 Masters', 'ACS14 Professional', 'ACS14 PhD',\n",
    "       'ACS13 Masters', 'ACS13 Professional', 'ACS13 PhD',\n",
    "       'ACS12 Masters', 'ACS12 Professional', 'ACS12 PhD']])\n",
    "\n",
    "y=edstat_int_clean.interpolate(method='linear',axis=1, inplace=False)\n",
    "\n",
    "z=y.fillna(method='bfill', axis=1)\n",
    "z['Tract'] = rentstat_int['GEO.id2']\n",
    "zz = z.dropna(axis=0)\n",
    "zz = zz.replace(np.inf, np.nan)\n",
    "zz = zz.dropna()\n",
    "\n",
    "edstat_moment = zz\n",
    "edstat_moment = zz.reset_index(drop=True, inplace=False)\n",
    "\n",
    "# edstat_moment.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "282"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbs=pd.Series([0,1,2,3,4,5])\n",
    "# First, for Households Achieving Masters Degree\n",
    "results_HHMSTR = {}\n",
    "for i in range(len(edstat_moment)):\n",
    "    testdata = pd.Series(edstat_moment.loc[i,['ACS17 Masters','ACS16 Masters','ACS15 Masters', 'ACS14 Masters','ACS13 Masters', 'ACS12 Masters']])\n",
    "    m,b,r,p,std_err = stats.linregress(numbs.astype(float), testdata.astype(float))\n",
    "    results_HHMSTR[i]=(m,b,r,p,std_err)\n",
    "len(results_HHMSTR)\n",
    "\n",
    "\n",
    "# Now, for Households Achieving Professional Degree\n",
    "results_HHPRD = {}\n",
    "for i in range(len(edstat_moment)):\n",
    "    testdata = pd.Series(edstat_moment.loc[i,['ACS17 Masters','ACS16 Masters', \n",
    "       'ACS15 Masters', 'ACS14 Masters','ACS13 Masters', 'ACS12 Masters']])\n",
    "    m,b,r,p,std_err = stats.linregress(numbs.astype(float), testdata.astype(float))\n",
    "    results_HHPRD[i]=(m,b,r,p,std_err)\n",
    "len(results_HHPRD)\n",
    "\n",
    "# Finally, for Households Achieving a Ph.D.\n",
    "\n",
    "results_HHPHD = {}\n",
    "for i in range(len(edstat_moment)):\n",
    "    testdata = pd.Series(edstat_moment.loc[i,['ACS17 PhD','ACS16 PhD', \n",
    "       'ACS15 PhD', 'ACS14 PhD','ACS13 PhD', 'ACS12 PhD']])\n",
    "    m,b,r,p,std_err = stats.linregress(numbs.astype(float), testdata.astype(float))\n",
    "    results_HHPHD[i]=(m,b,r,p,std_err)\n",
    "\n",
    "len(results_HHPHD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 282 entries, 0 to 281\n",
      "Data columns (total 2 columns):\n",
      "0         282 non-null float64\n",
      "Tracts    282 non-null object\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 6.6+ KB\n"
     ]
    }
   ],
   "source": [
    "HHMSTR_k = pd.DataFrame(results_HHMSTR).T\n",
    "HHMSTR_k['Tracts'] = edstat_moment['Tract']\n",
    "HHMSTR_k.drop(labels=[1,2,3,4], axis=1, inplace=True)\n",
    "HHMSTR_k.rename(columns = {0:'Mastrs_m'})\n",
    "HHMSTR_k.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "HHMSTR_k.to_csv('/users/richardkornblith/Data_Science/NYCHR/Data_for_NYCHR/HHMSTR_k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 282 entries, 0 to 281\n",
      "Data columns (total 2 columns):\n",
      "0         282 non-null float64\n",
      "Tracts    282 non-null object\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 6.6+ KB\n"
     ]
    }
   ],
   "source": [
    "HHPRD_k =  pd.DataFrame(results_HHPRD).T\n",
    "HHPRD_k['Tracts'] = edstat_moment['Tract']\n",
    "HHPRD_k.drop(labels=[1,2,3,4], axis=1, inplace=True)\n",
    "HHPRD_k.rename(columns = {0:'Profs_m'})\n",
    "HHPRD_k.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "HHPRD_k.to_csv('/users/richardkornblith/Data_Science/NYCHR/Data_for_NYCHR/HHPRD_k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 282 entries, 0 to 281\n",
      "Data columns (total 2 columns):\n",
      "0         282 non-null float64\n",
      "Tracts    282 non-null object\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 6.6+ KB\n"
     ]
    }
   ],
   "source": [
    "HHPHD_k =  pd.DataFrame(results_HHPHD).T\n",
    "HHPHD_k['Tracts'] = edstat_moment['Tract']\n",
    "HHPHD_k.drop(labels=[1,2,3,4], axis=1, inplace=True)\n",
    "HHPHD_k.rename(columns = {0:'PhD_m'})\n",
    "HHPHD_k.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "HHPHD_k.to_csv('/users/richardkornblith/Data_Science/NYCHR/Data_for_NYCHR/HHPHD_k.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table B19054 (Interest, Dividends or Net Rental Income)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Income from interest, dividends or net rental income constitutes the bulk of noncapital returns from investment -- that is 'passive income'.  Table B19054 estimates whether during the preceding twelve month period the number of households that had, or did not have, any passive income.  The receipt of passive income may be a relevant factor in restaurant usage to the extent that it indicates that the household has invested wealth that might also support such usage.  That is, it is reasonable to assume that a household with investment income may partake of restaurants of the type considered here, while a household with no investment income probably would not partake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACS_list = [('ACS17_5YR_FULL_N',True),('ACS16_5YR_FULL_N',True),('ACS15_5YR_FULL_N',True),('ACS14_5YR_FULL_N',False),\n",
    "            ('ACS13_5YR_FULL_N',False),('ACS12_5YR_FULL_N',False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "B19054_current_fields = ['GEO.id2','HD01_VD01','HD01_VD02','HD01_VD03']\n",
    "current_names = ['Total','Passive Income','No Passive Income']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pds={}\n",
    "\n",
    "for i in range(len(ACS_list)):\n",
    "    subdir=ACS_list[i]\n",
    "    tr = '/users/richardkornblith/Data_Science/NYCHR/Data_for_NYCHR/'+subdir[0]+'/'\n",
    "    csv_file = fnmatch.filter(os.listdir(tr),'*054*with_ann.csv')\n",
    "    full_path = tr+csv_file[0]\n",
    "    cols = B19054_current_fields\n",
    "    col_names = current_names\n",
    "    df_t = pd.read_csv(full_path, index_col='GEO.id2',usecols=cols)\n",
    "    df_t.columns = [ACS_list[i][0][0:5]+\" \"+col_names[j] for j in range(len(col_names))]\n",
    "    df_t.drop(labels='Id2', inplace=True)\n",
    "    pds[ACS_list[i][0]]=df_t\n",
    "    \n",
    "# pds.items()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pincstat=pd.concat([pds[ACS_list[0][0]],pds[ACS_list[1][0]],pds[ACS_list[2][0]],pds[ACS_list[3][0]],pds[ACS_list[4][0]],pds[ACS_list[5][0]]],axis=1)\n",
    "pincstat_int=pincstat\n",
    "# pincstat_int.head(10)\n",
    "# pincstat_int.columns\n",
    "# pincstat_int.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now we normalize the data by division of the number of households reporting a receipt or non-receipt of passive income  \n",
    "# by the total number of households reporting on passive income.  In the cases where no households reported in\n",
    "# a particular survey, the resulting division by zero, resulting in a missing data 'NaN' or 'inf' entry, will be addressed below.\n",
    "\n",
    "pincstat_n=pd.DataFrame()\n",
    "\n",
    "pincstat['ACS17 Total'] = pincstat['ACS17 Total'].astype(float)\n",
    "pincstat['ACS16 Total'] = pincstat['ACS16 Total'].astype(float)\n",
    "pincstat['ACS15 Total'] = pincstat['ACS15 Total'].astype(float)\n",
    "pincstat['ACS14 Total'] = pincstat['ACS14 Total'].astype(float)\n",
    "pincstat['ACS13 Total'] = pincstat['ACS13 Total'].astype(float)\n",
    "pincstat['ACS12 Total'] = pincstat['ACS12 Total'].astype(float)\n",
    "\n",
    "pincstat['ACS17 Passive Income'] = pincstat['ACS17 Passive Income'].astype(float)\n",
    "pincstat['ACS17 No Passive Income'] = pincstat['ACS17 No Passive Income'].astype(float)\n",
    "pincstat['ACS16 Passive Income'] = pincstat['ACS16 Passive Income'].astype(float)\n",
    "pincstat['ACS16 No Passive Income'] = pincstat['ACS16 No Passive Income'].astype(float)\n",
    "pincstat['ACS15 Passive Income'] = pincstat['ACS15 Passive Income'].astype(float)\n",
    "pincstat['ACS15 No Passive Income'] = pincstat['ACS15 No Passive Income'].astype(float)\n",
    "pincstat['ACS14 Passive Income'] = pincstat['ACS14 Passive Income'].astype(float)\n",
    "pincstat['ACS14 No Passive Income'] = pincstat['ACS14 No Passive Income'].astype(float)\n",
    "pincstat['ACS13 Passive Income'] = pincstat['ACS13 Passive Income'].astype(float)\n",
    "pincstat['ACS13 No Passive Income'] = pincstat['ACS13 No Passive Income'].astype(float)\n",
    "pincstat['ACS12 Passive Income'] = pincstat['ACS12 Passive Income'].astype(float)\n",
    "pincstat['ACS12 No Passive Income'] = pincstat['ACS12 No Passive Income'].astype(float)\n",
    "\n",
    "pincstat_n['ACS17 Passive Income']= pincstat_int['ACS17 Passive Income'].div(pincstat_int['ACS17 Total'],axis=0)\n",
    "pincstat_n['ACS17 No Passive Income']= pincstat_int['ACS17 No Passive Income'].div(pincstat_int['ACS17 Total'],axis=0)\n",
    "pincstat_n['ACS16 Passive Income']= pincstat_int['ACS16 Passive Income'].div(pincstat_int['ACS16 Total'],axis=0)\n",
    "pincstat_n['ACS16 No Passive Income']= pincstat_int['ACS16 No Passive Income'].div(pincstat_int['ACS16 Total'],axis=0)\n",
    "pincstat_n['ACS15 Passive Income']= pincstat_int['ACS15 Passive Income'].div(pincstat_int['ACS15 Total'],axis=0)\n",
    "pincstat_n['ACS15 No Passive Income']= pincstat_int['ACS15 No Passive Income'].div(pincstat_int['ACS15 Total'],axis=0)\n",
    "pincstat_n['ACS14 Passive Income']= pincstat_int['ACS14 Passive Income'].div(pincstat_int['ACS14 Total'],axis=0)\n",
    "pincstat_n['ACS14 No Passive Income']= pincstat_int['ACS14 No Passive Income'].div(pincstat_int['ACS14 Total'],axis=0)\n",
    "pincstat_n['ACS13 Passive Income']= pincstat_int['ACS13 Passive Income'].div(pincstat_int['ACS13 Total'],axis=0)\n",
    "pincstat_n['ACS13 No Passive Income']= pincstat_int['ACS13 No Passive Income'].div(pincstat_int['ACS13 Total'],axis=0)\n",
    "pincstat_n['ACS12 Passive Income']= pincstat_int['ACS12 Passive Income'].div(pincstat_int['ACS12 Total'],axis=0)\n",
    "pincstat_n['ACS12 No Passive Income']= pincstat_int['ACS12 No Passive Income'].div(pincstat_int['ACS12 Total'],axis=0)\n",
    "\n",
    "# pincstat_int_idx.info()\n",
    "# pincstat_int.head(10)\n",
    "# pincstat_int_idx.columns\n",
    "# pincstat_int_idx.info()\n",
    "# pincstat_n.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will address the missing data. We first will interpolate between valid data entries and after that we will try backfilling.\n",
    "# Any remaining instances that have missing data (np.inf or NaN) will be dropped. We will be careful to maintain the mapping of indices to\n",
    "# census tracts\n",
    " \n",
    "pincstat_int = pincstat_n.reset_index(drop=False, inplace=False)\n",
    "pincstat_int_clean= pd.DataFrame(pincstat_int[['ACS17 Passive Income','ACS17 No Passive Income','ACS16 Passive Income', 'ACS16 No Passive Income',\n",
    "                                               'ACS15 Passive Income', 'ACS15 No Passive Income','ACS14 Passive Income', 'ACS14 No Passive Income',\n",
    "                                                'ACS13 Passive Income', 'ACS13 No Passive Income', 'ACS12 Passive Income', 'ACS12 No Passive Income']])\n",
    "\n",
    "y=pincstat_int_clean.interpolate(method='linear',axis=1, inplace=False)\n",
    "\n",
    "z=y.fillna(method='bfill', axis=1)\n",
    "z['Tract'] = rentstat_int['GEO.id2']\n",
    "zz = z.dropna(axis=0)\n",
    "zz = zz.replace(np.inf, np.nan)\n",
    "zz = zz.dropna()\n",
    "\n",
    "pincstat_moment = zz\n",
    "pincstat_moment = zz.reset_index(drop=True, inplace=False)\n",
    "# pincstat_moment.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## numbs=pd.Series([0,1,2,3,4,5])\n",
    "# First, for Households Receiving Passive Income\n",
    "results_HHPINC = {}\n",
    "for i in range(len(pincstat_moment)):\n",
    "    testdata = pd.Series(pincstat_moment.loc[i,['ACS17 Passive Income','ACS16 Passive Income','ACS15 Passive Income',\n",
    "                                                'ACS14 Passive Income','ACS13 Passive Income','ACS12 Passive Income']])\n",
    "    m,b,r,p,std_err = stats.linregress(numbs.astype(float), testdata.astype(float))\n",
    "    results_HHPINC[i]=(m,b,r,p,std_err)\n",
    "len(results_HHPINC)\n",
    "\n",
    "\n",
    "# Now, for Households Receiving No Passive Income\n",
    "results_HHNPINC = {}\n",
    "for i in range(len(pincstat_moment)):\n",
    "    testdata = pd.Series(pincstat_moment.loc[i,['ACS17 No Passive Income','ACS16 No Passive Income', \n",
    "       'ACS15 No Passive Income', 'ACS14 No Passive Income','ACS13 No Passive Income', 'ACS12 No Passive Income']])\n",
    "    m,b,r,p,std_err = stats.linregress(numbs.astype(float), testdata.astype(float))\n",
    "    results_HHNPINC[i]=(m,b,r,p,std_err)\n",
    "\n",
    "len(results_HHNPINC)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "HHPINC_k=pd.DataFrame(results_HHPINC).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 280 entries, 0 to 279\n",
      "Data columns (total 2 columns):\n",
      "0         280 non-null float64\n",
      "Tracts    280 non-null object\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 6.6+ KB\n"
     ]
    }
   ],
   "source": [
    "HHPINC_k['Tracts'] = pincstat_moment['Tract']\n",
    "HHPINC_k.drop(labels=[1,2,3,4], axis=1, inplace=True)\n",
    "HHPINC_k.rename(columns = {0:'PI_m'})\n",
    "HHPINC_k.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "HHPINC_k.to_csv('/users/richardkornblith/Data_Science/NYCHR/Data_for_NYCHR/HHPINC_k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 282 entries, 0 to 281\n",
      "Data columns (total 2 columns):\n",
      "0         282 non-null float64\n",
      "Tracts    282 non-null object\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 6.6+ KB\n"
     ]
    }
   ],
   "source": [
    "HHNPINC_k = pd.DataFrame(results_HHNPINC).T\n",
    "\n",
    "HHNPINC_k['Tracts'] = pincstat_moment['Tract']\n",
    "HHNPINC_k.drop(labels=[1,2,3,4], axis=1, inplace=True)\n",
    "HHNPINC_k.rename(columns = {0:'no_PI_m'})\n",
    "HHMSTR_k.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "HHNPINC_k.to_csv('/users/richardkornblith/Data_Science/NYCHR/Data_for_NYCHR/HHNPINC_k.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table B19001 (Household Income in Past Twelve Months)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table B19001 estimates twelve-month household income by housing unit on the basis of income brackets ranging from under $10,000 to over $200,000.  It is likely that income level differentiation is relevant to the decision on whether to partake of restaurants of the type we envision.  For purposes of this study, we look to momentum in two brackets:  households with income of between $150,000 and $199,000; and households with income above that level.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACS_list = [('ACS17_5YR_FULL_N',True),('ACS16_5YR_FULL_N',True),('ACS15_5YR_FULL_N',True),('ACS14_5YR_FULL_N',False),\n",
    "            ('ACS13_5YR_FULL_N',False),('ACS12_5YR_FULL_N',False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Total', '150k-199k', '200k and Over']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B19001_current_fields = ['GEO.id2','HD01_VD01','HD01_VD16','HD01_VD17']\n",
    "current_names = ['Total','150k-199k','200k and Over']\n",
    "current_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pds={}\n",
    "\n",
    "for i in range(len(ACS_list)):\n",
    "    subdir=ACS_list[i]\n",
    "    tr = '/users/richardkornblith/Data_Science/NYCHR/Data_for_NYCHR/'+subdir[0]+'/'\n",
    "    csv_file = fnmatch.filter(os.listdir(tr),'*9001*with_ann.csv')\n",
    "    full_path = tr+csv_file[0]\n",
    "    cols = B19001_current_fields\n",
    "    col_names = current_names\n",
    "    df_t = pd.read_csv(full_path, index_col='GEO.id2',usecols=cols)\n",
    "    df_t.columns = [ACS_list[i][0][0:5]+\" \"+col_names[j] for j in range(len(col_names))]\n",
    "    df_t.drop(labels='Id2', inplace=True)\n",
    "    pds[ACS_list[i][0]]=df_t\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ACS17 Total', 'ACS17 150k-199k', 'ACS17 200k and Over', 'ACS16 Total',\n",
       "       'ACS16 150k-199k', 'ACS16 200k and Over', 'ACS15 Total',\n",
       "       'ACS15 150k-199k', 'ACS15 200k and Over', 'ACS14 Total',\n",
       "       'ACS14 150k-199k', 'ACS14 200k and Over', 'ACS13 Total',\n",
       "       'ACS13 150k-199k', 'ACS13 200k and Over', 'ACS12 Total',\n",
       "       'ACS12 150k-199k', 'ACS12 200k and Over'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gincstat=pd.concat([pds[ACS_list[0][0]],pds[ACS_list[1][0]],pds[ACS_list[2][0]],pds[ACS_list[3][0]],pds[ACS_list[4][0]],pds[ACS_list[5][0]]],axis=1)\n",
    "gincstat.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Now we normalize the data by division of the number of households reporting a level of educational attainment of interest here \n",
    "# by the total number of households reporting educational attainment at any level in the respective surveys.  In the cases \n",
    "# where no households reported in\n",
    "# a particular survey, the resulting division by zero, resulting in a missing data 'NaN' entry, will be addressed below.\n",
    "\n",
    "gincstat_n=pd.DataFrame()\n",
    "\n",
    "gincstat['ACS17 Total'] = gincstat['ACS17 Total'].astype(float)\n",
    "gincstat['ACS16 Total'] = gincstat['ACS16 Total'].astype(float)\n",
    "gincstat['ACS15 Total'] = gincstat['ACS15 Total'].astype(float)\n",
    "gincstat['ACS14 Total'] = gincstat['ACS14 Total'].astype(float)\n",
    "gincstat['ACS13 Total'] = gincstat['ACS13 Total'].astype(float)\n",
    "gincstat['ACS12 Total'] = gincstat['ACS12 Total'].astype(float)\n",
    "\n",
    "gincstat['ACS17 200k and Over'] = gincstat['ACS17 200k and Over'].astype(float)\n",
    "gincstat['ACS17 150k-199k'] = gincstat['ACS17 150k-199k'].astype(float)\n",
    "gincstat['ACS16 200k and Over'] = gincstat['ACS16 200k and Over'].astype(float)\n",
    "gincstat['ACS16 150k-199k'] = gincstat['ACS16 150k-199k'].astype(float)\n",
    "gincstat['ACS15 200k and Over'] = gincstat['ACS15 200k and Over'].astype(float)\n",
    "gincstat['ACS15 150k-199k'] = gincstat['ACS15 150k-199k'].astype(float)\n",
    "gincstat['ACS14 150k-199k'] = gincstat['ACS14 150k-199k'].astype(float)\n",
    "gincstat['ACS14 200k and Over'] = gincstat['ACS14 200k and Over'].astype(float)\n",
    "gincstat['ACS13 150k-199k'] = gincstat['ACS13 150k-199k'].astype(float)\n",
    "gincstat['ACS13 200k and Over'] = gincstat['ACS13 200k and Over'].astype(float)\n",
    "gincstat['ACS12 150k-199k'] = gincstat['ACS12 150k-199k'].astype(float)\n",
    "gincstat['ACS12 200k and Over'] = gincstat['ACS12 200k and Over'].astype(float)\n",
    "\n",
    "gincstat_n['ACS17 200k and Over'] = gincstat['ACS17 200k and Over'].div(gincstat['ACS17 Total'])\n",
    "gincstat_n['ACS17 150k-199k'] = gincstat['ACS17 150k-199k'].div(gincstat['ACS17 Total'])\n",
    "gincstat['ACS16 200k and Over']\n",
    "gincstat_n['ACS16 200k and Over'] = gincstat['ACS16 200k and Over'].div(gincstat['ACS16 Total'])\n",
    "gincstat_n['ACS16 150k-199k'] = gincstat['ACS16 150k-199k'].div(gincstat['ACS16 Total'])\n",
    "gincstat_n['ACS15 200k and Over'] = gincstat['ACS15 200k and Over'].div(gincstat['ACS15 Total'])\n",
    "gincstat_n['ACS15 150k-199k'] = gincstat['ACS15 150k-199k'].div(gincstat['ACS15 Total'])\n",
    "gincstat_n['ACS14 200k and Over'] = gincstat['ACS14 200k and Over'].div(gincstat['ACS14 Total'])\n",
    "gincstat_n['ACS14 150k-199k'] = gincstat['ACS14 150k-199k'].div(gincstat['ACS14 Total'])\n",
    "gincstat_n['ACS13 200k and Over'] = gincstat['ACS13 200k and Over'].div(gincstat['ACS13 Total'])\n",
    "gincstat_n['ACS13 150k-199k'] = gincstat['ACS13 150k-199k'].div(gincstat['ACS13 Total'])\n",
    "gincstat_n['ACS12 200k and Over'] = gincstat['ACS12 200k and Over'].div(gincstat['ACS12 Total'])\n",
    "gincstat_n['ACS12 150k-199k'] = gincstat['ACS12 150k-199k'].div(gincstat['ACS12 Total'])\n",
    "\n",
    "# gincstat_n.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will address the missing data. We first will interpolate between valid data entries and after that we will try backfilling.\n",
    "# Any remaining instances that have missing data (np.inf or NaN) will be dropped. We will be careful to maintain the mapping of indices to\n",
    "# census tracts\n",
    " \n",
    "gincstat_int=gincstat_n.reset_index(drop=False, inplace=False)\n",
    "gincstat_int_clean= pd.DataFrame(gincstat_int[['ACS17 150k-199k', 'ACS17 200k and Over','ACS16 150k-199k', 'ACS16 200k and Over',\n",
    "                                               'ACS15 150k-199k', 'ACS15 200k and Over','ACS14 150k-199k', 'ACS14 200k and Over',\n",
    "                                               'ACS13 150k-199k', 'ACS13 200k and Over','ACS12 150k-199k', 'ACS12 200k and Over']])\n",
    "y=gincstat_int_clean.interpolate(method='linear',axis=1, inplace=False)\n",
    "\n",
    "z=y.fillna(method='bfill', axis=1)\n",
    "z['Tract'] = gincstat_int['GEO.id2']\n",
    "zz=z.dropna(axis=0)\n",
    "zz = zz.replace(np.inf, np.nan)\n",
    "zz = zz.dropna()\n",
    "\n",
    "gincstat_moment = zz\n",
    "gincstat_moment = zz.reset_index(drop=True, inplace=False)\n",
    "# gincstat_moment.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbs=pd.Series([0,1,2,3,4,5])\n",
    "# First, for Households of 150k-199k Income\n",
    "results_HHMIDI = {}\n",
    "for i in range(len(gincstat_moment)):\n",
    "    testdata = pd.Series(gincstat_moment.loc[i,['ACS17 150k-199k','ACS16 150k-199k','ACS15 150k-199k', 'ACS14 150k-199k','ACS13 150k-199k',\n",
    "                                              'ACS12 150k-199k']])\n",
    "    m,b,r,p,std_err = stats.linregress(numbs.astype(float), testdata.astype(float))\n",
    "    results_HHMIDI[i]=(m,b,r,p,std_err)\n",
    "len(results_HHMIDI)\n",
    "\n",
    "\n",
    "# Now, for Households of 200k and over Income\n",
    "results_HHHII = {}\n",
    "for i in range(len(gincstat_moment)):\n",
    "    testdata = pd.Series(gincstat_moment.loc[i,['ACS17 200k and Over','ACS16 200k and Over', \n",
    "       'ACS15 200k and Over', 'ACS14 200k and Over','ACS13 200k and Over','ACS12 200k and Over']])\n",
    "    m,b,r,p,std_err = stats.linregress(numbs.astype(float), testdata.astype(float))\n",
    "    results_HHHII[i]=(m,b,r,p,std_err)\n",
    "len(results_HHHII)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 280 entries, 0 to 279\n",
      "Data columns (total 2 columns):\n",
      "0         280 non-null float64\n",
      "Tracts    280 non-null object\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 6.6+ KB\n"
     ]
    }
   ],
   "source": [
    "HHHII_k =pd.DataFrame(results_HHHII).T\n",
    "HHHII_k['Tracts'] = gincstat_moment['Tract']\n",
    "HHHII_k.drop(labels=[1,2,3,4], axis=1, inplace=True)\n",
    "HHHII_k.rename(columns = {0:'highinc_m'})\n",
    "HHHII_k.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "HHHII_k.to_csv('/users/richardkornblith/Data_Science/NYCHR/Data_for_NYCHR/HHHII_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 280 entries, 0 to 279\n",
      "Data columns (total 2 columns):\n",
      "0         280 non-null float64\n",
      "Tracts    280 non-null object\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 6.6+ KB\n"
     ]
    }
   ],
   "source": [
    "HHMIDI_k=pd.DataFrame(results_HHMIDI).T\n",
    "HHMIDI_k['Tracts'] = gincstat_moment['Tract']\n",
    "HHMIDI_k.drop(labels=[1,2,3,4], axis=1, inplace=True)\n",
    "HHMIDI_k.rename(columns = {0:'midinc_m'})\n",
    "HHMIDI_k.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "HHMIDI_k.to_csv('/users/richardkornblith/Data_Science/NYCHR/Data_for_NYCHR/HHMIDI_df.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
